import torch
import math
import sys
import isaaclab.sim as sim_utils
from isaaclab.assets import AssetBaseCfg, RigidObjectCfg
from isaaclab.envs import ManagerBasedRLEnv, ManagerBasedRLEnvCfg, mdp
from isaaclab.scene import InteractiveSceneCfg
from isaaclab.sensors import CameraCfg, Camera, ContactSensor, ContactSensorCfg
from isaaclab.managers import SceneEntityCfg, RewardTermCfg, ObservationGroupCfg, ObservationTermCfg, TerminationTermCfg, EventTermCfg, CurriculumTermCfg
from isaaclab.utils import configclass
from isaaclab.utils.noise import GaussianNoiseCfg
from isaaclab.utils.math import wrap_to_pi, quat_apply_inverse, euler_xyz_from_quat, quat_from_euler_xyz
# [æ¶æ„å¸ˆV3.4æœ€ç»ˆç‰ˆ] 0.46.xç‰ˆæœ¬ä¸“ç”¨ï¼šHfå‰ç¼€ç±»å
from isaaclab.terrains import TerrainGeneratorCfg, TerrainImporterCfg

# Isaac Lab 0.46.x ä½¿ç”¨ Hf å‰ç¼€ï¼ˆHeight Fieldçš„ç¼©å†™ï¼‰
from isaaclab.terrains.height_field import (
    HfTerrainBaseCfg,              # å¹³åœ°ï¼ˆæ›¿ä»£MeshPlaneTerrainCfgï¼‰
    HfRandomUniformTerrainCfg,     # éšæœºéšœç¢ï¼ˆæ›¿ä»£MoundsTerrainCfgï¼‰
    HfDiscreteObstaclesTerrainCfg, # è¿·å®«ï¼ˆä¿æŒåŸåï¼‰
)

TERRAIN_GEN_AVAILABLE = True
from dashgo_assets import DASHGO_D1_CFG
from dashgo_config import DashGoROSParams  # æ–°å¢: å¯¼å…¥ROSå‚æ•°é…ç½®ç±»

# =============================================================================
# è®­ç»ƒè¶…å‚æ•°å¸¸é‡å®šä¹‰ï¼ˆæ¥è‡ª train_cfg_v2.yaml å’Œ ROS é…ç½®ï¼‰
# =============================================================================

# PPOè®­ç»ƒå‚æ•°
PPO_CONFIG = {
    "seed": 42,                # éšæœºç§å­ï¼ˆä¿è¯å¯é‡å¤æ€§ï¼‰
    "num_steps_per_env": 480,  # æ¯ä¸ªç¯å¢ƒçš„æ­¥æ•°ï¼ˆçº¦32ç§’ @ 15fpsï¼‰
    "num_mini_batches": 4,     # å°æ‰¹é‡æ•°é‡
    "entropy_coef": 0.01,      # ç†µç³»æ•°ï¼ˆé¼“åŠ±æ¢ç´¢ï¼Œ0.01ä¸ºä¿å®ˆå€¼ï¼‰
    "max_iterations": 10000,   # æœ€å¤§è®­ç»ƒè¿­ä»£æ¬¡æ•°
    "save_interval": 50,       # æ¨¡å‹ä¿å­˜é—´éš”
}

# ç¥ç»ç½‘ç»œæ¶æ„å‚æ•°
NETWORK_CONFIG = {
    "init_noise_std": 0.8,  # ç­–ç•¥åˆå§‹åŒ–å™ªå£°æ ‡å‡†å·®ï¼ˆ0.8ä¸ºRSLæ¨èå€¼ï¼‰
    "actor_hidden_dims": [512, 256, 128],  # Actorç½‘ç»œéšè—å±‚
    "critic_hidden_dims": [512, 256, 128], # Criticç½‘ç»œéšè—å±‚
    "activation": "elu",     # æ¿€æ´»å‡½æ•°
}

# PPOç®—æ³•å‚æ•°
ALGORITHM_CONFIG = {
    "value_loss_coef": 1.0,  # å€¼å‡½æ•°æŸå¤±ç³»æ•°
    "clip_param": 0.2,       # PPOè£å‰ªå‚æ•°ï¼ˆæ ‡å‡†å€¼0.2ï¼‰
    "num_learning_epochs": 5,  # æ¯æ¬¡æ›´æ–°çš„å­¦ä¹ è½®æ•°
    "learning_rate": 1.0e-4,  # å­¦ä¹ ç‡ï¼ˆä»3e-4é™åˆ°1e-4æé«˜ç¨³å®šæ€§ï¼‰
    "max_grad_norm": 1.0,     # æ¢¯åº¦è£å‰ªé˜ˆå€¼
    "gamma": 0.99,            # æŠ˜æ‰£å› å­ï¼ˆ0.99å¹³è¡¡çŸ­æœŸå’Œé•¿æœŸå¥–åŠ±ï¼‰
    "lam": 0.95,              # GAE(lambda)å‚æ•°
    "desired_kl": 0.01,       # æœŸæœ›KLæ•£åº¦ï¼ˆç”¨äºè‡ªé€‚åº”å­¦ä¹ ç‡ï¼‰
}

# æœºå™¨äººè¿åŠ¨å‚æ•°ï¼ˆæ¥è‡ªROSé…ç½®ï¼‰
MOTION_CONFIG = {
    "max_lin_vel": 0.3,       # æœ€å¤§çº¿é€Ÿåº¦ (m/sï¼Œæ¥è‡ªROS max_vel_x)
    "max_ang_vel": 1.0,       # æœ€å¤§è§’é€Ÿåº¦ (rad/sï¼Œæ¥è‡ªROS max_rot_vel)
    "max_accel_lin": 1.0,     # æœ€å¤§çº¿åŠ é€Ÿåº¦ (m/sÂ²)
    "max_accel_ang": 0.6,     # æœ€å¤§è§’åŠ é€Ÿåº¦ (rad/sÂ²)
    "max_wheel_vel": 5.0,     # æœ€å¤§è½®é€Ÿ
    "control_dt": 0.1,        # æ§åˆ¶æ—¶é—´æ­¥ (sï¼Œå³10Hzæ§åˆ¶é¢‘ç‡)
}

# å¥–åŠ±å‡½æ•°å‚æ•°ï¼ˆæƒé‡å’Œé˜ˆå€¼ï¼‰
# [Geo-Distill V3.0] åŸºäºåšå¼ˆè®ºçš„å‚æ•°è®¾è®¡
REWARD_CONFIG = {
    # [1] æˆ˜æœ¯æ€§å€’è½¦ï¼š1:100 çš„ä»£ä»·æ¯”
    # åšå¼ˆè®ºæ¨å¯¼ï¼šå€’è½¦2ç§’ä»£ä»·(10) << æ’å¢™ä»£ä»·(500)
    "backward_penalty": 5.0,       # âœ… V3.0: ä»0.05æé«˜åˆ°5.0ï¼ˆ100å€ï¼‰
    "collision_penalty": 500.0,    # âœ… V3.0: ä»0.5æé«˜åˆ°500.0ï¼ˆ1000å€ï¼‰

    # [2] æ—‹è½¬æŠ‘åˆ¶ï¼šé˜²æ­¢åŸåœ°é™€èº
    "angular_penalty": 0.5,        # âœ… V3.0: æ–°å¢ï¼Œæ—‹è½¬1rad/sæ‰£0.5åˆ†

    # [3] åœè½¦è¯±å¯¼ï¼šåŠ¿èƒ½äº•
    "terminal_reward": 100.0,      # âœ… V3.0: æ–°å¢ï¼Œåªæœ‰åœç¨³æ‰ç»™100åˆ†
    "stop_dist_thresh": 0.25,      # âœ… V3.0: è·ç¦»é˜ˆå€¼0.25m
    "stop_vel_thresh": 0.1,        # âœ… V3.0: é€Ÿåº¦é˜ˆå€¼0.1m/s

    # ä¿ç•™åŸæœ‰å‚æ•°
    "progress_weight": 1.0,
    "facing_threshold": 0.8,
    "high_speed_threshold": 0.25,
    "high_speed_reward": 0.2,
    "safe_distance": 0.2,
    "collision_decay": 4.0,
    "facing_reward_scale": 0.5,
    "facing_angle_scale": 0.5,
    "alive_penalty": 1.0,

    # [V3.0] æ‰©å¤§å¥–åŠ±èŒƒå›´ä»¥å®¹çº³terminal_reward
    "reward_clip_min": -20.0,  # âœ… V3.0: ä»-10.0æ‰©å¤§åˆ°-20.0
    "reward_clip_max": 120.0,  # âœ… V3.0: ä»10.0æ‰©å¤§åˆ°120.0ï¼ˆå®¹çº³100åˆ†å¤§å¥–ï¼‰
}

# è§‚æµ‹å¤„ç†å‚æ•°
OBSERVATION_CONFIG = {
    "max_distance": 50.0,  # æœ€å¤§è·ç¦»æˆªæ–­ (mï¼Œé˜²æ­¢æ•°å€¼æº¢å‡º)
    "epsilon": 1e-6,       # æ•°å€¼ç¨³å®šæ€§epsilonï¼ˆé˜²æ­¢é™¤é›¶ï¼‰
}

# =============================================================================
# è¾…åŠ©å‡½æ•°ï¼šæ£€æµ‹æ˜¯å¦ headless æ¨¡å¼
# =============================================================================
def is_headless_mode():
    """æ£€æµ‹å‘½ä»¤è¡Œå‚æ•°ä¸­æ˜¯å¦æœ‰ --headless"""
    return "--headless" in sys.argv

# =============================================================================
# 1. è‡ªå®šä¹‰åŠ¨ä½œç±» (Action Wrapper) - ä¿æŒä¸å˜
# =============================================================================

class UniDiffDriveAction(mdp.actions.JointVelocityAction):
    """
    å·®é€Ÿé©±åŠ¨æœºå™¨äººçš„åŠ¨ä½œè½¬æ¢å™¨

    å¼€å‘åŸºå‡†: Isaac Sim 4.5 + Ubuntu 20.04
    å®˜æ–¹æ–‡æ¡£: https://isaac-sim.github.io/IsaacLab/main/reference/api/isaaclab/mdp/actions.html
    å‚è€ƒç¤ºä¾‹: isaaclab/exts/omni_isaac_lab_tasks/omni/isaac/lab/tasks/locomotion/velocity/action.py

    åŠŸèƒ½:
        - å°†[çº¿é€Ÿåº¦, è§’é€Ÿåº¦]è½¬æ¢ä¸º[å·¦è½®é€Ÿåº¦, å³è½®é€Ÿåº¦]
        - åº”ç”¨é€Ÿåº¦é™åˆ¶ï¼ˆå¯¹é½ROSé…ç½®ï¼‰
        - åº”ç”¨åŠ é€Ÿåº¦å¹³æ»‘ï¼ˆå¯¹é½ROSé…ç½®ï¼‰
        - è£å‰ªåˆ°æ‰§è¡Œå™¨é™åˆ¶

    å‚æ•°æ¥æº:
        - wheel_radius: 0.0632mï¼ˆROSé…ç½®: wheel_diameter/2ï¼‰
        - track_width: 0.342mï¼ˆROSé…ç½®: wheel_trackï¼‰
        - max_lin_vel: 0.3 m/sï¼ˆROSé…ç½®: max_vel_xï¼‰
        - max_ang_vel: 1.0 rad/sï¼ˆROSé…ç½®: max_vel_thetaï¼‰
        - max_accel_lin: 1.0 m/sÂ²ï¼ˆROSé…ç½®: acc_lim_xï¼‰
        - max_accel_ang: 0.6 rad/sÂ²ï¼ˆROSé…ç½®: acc_lim_thetaï¼‰

    è¿åŠ¨å­¦æ¨¡å‹:
        v_left = (v - w * track_width / 2) / wheel_radius
        v_right = (v + w * track_width / 2) / wheel_radius

    å†å²ä¿®æ”¹:
        - 2024-01-23: æ·»åŠ é€Ÿåº¦å’ŒåŠ é€Ÿåº¦é™åˆ¶ï¼ˆcommit 9dad5deï¼‰
        - 2024-01-23: ä¿®æ­£è½®è·å‚æ•°ï¼ˆcommit 81d6cebï¼‰
    """
    def __init__(self, cfg, env):
        super().__init__(cfg, env)

        # âœ… ä»ROSé…ç½®è¯»å–å‚æ•°ï¼ˆé¿å…ç¡¬ç¼–ç ï¼‰
        ros_params = DashGoROSParams.from_yaml()
        self.wheel_radius = ros_params.wheel_radius  # wheel_diameter / 2.0
        self.track_width = ros_params.wheel_track

        self.prev_actions = None
        self.max_accel_lin = MOTION_CONFIG["max_accel_lin"]
        self.max_accel_ang = MOTION_CONFIG["max_accel_ang"]

    def process_actions(self, actions: torch.Tensor, *args, **kwargs):
        # å¯¹é½ROSé€Ÿåº¦é™åˆ¶
        max_lin_vel = MOTION_CONFIG["max_lin_vel"]
        max_ang_vel = MOTION_CONFIG["max_ang_vel"]

        # é€Ÿåº¦è£å‰ª
        target_v = torch.clamp(actions[:, 0] * max_lin_vel, -max_lin_vel, max_lin_vel)
        target_w = torch.clamp(actions[:, 1] * max_ang_vel, -max_ang_vel, max_ang_vel)

        # åŠ é€Ÿåº¦å¹³æ»‘
        if self.prev_actions is not None:
            dt = MOTION_CONFIG["control_dt"]
            delta_v = target_v - self.prev_actions[:, 0]
            delta_w = target_w - self.prev_actions[:, 1]
            max_delta_v = self.max_accel_lin * dt
            max_delta_w = self.max_accel_ang * dt
            delta_v = torch.clamp(delta_v, -max_delta_v, max_delta_v)
            delta_w = torch.clamp(delta_w, -max_delta_w, max_delta_w)
            target_v = self.prev_actions[:, 0] + delta_v
            target_w = self.prev_actions[:, 1] + delta_w

        self.prev_actions = torch.stack([target_v, target_w], dim=-1).clone()

        # å·®é€Ÿé©±åŠ¨è½¬æ¢
        v_left = (target_v - target_w * self.track_width / 2.0) / self.wheel_radius
        v_right = (target_v + target_w * self.track_width / 2.0) / self.wheel_radius

        # è£å‰ªåˆ°æ‰§è¡Œå™¨é™åˆ¶
        max_wheel_vel = MOTION_CONFIG["max_wheel_vel"]
        v_left = torch.clamp(v_left, -max_wheel_vel, max_wheel_vel)
        v_right = torch.clamp(v_right, -max_wheel_vel, max_wheel_vel)

        joint_actions = torch.stack([v_left, v_right], dim=-1)
        return super().process_actions(joint_actions, *args, **kwargs)

# =============================================================================
# 2. è§‚æµ‹å¤„ç† (Observation) - åŒ…å« NaN æ¸…æ´—
# =============================================================================

def obs_target_polar(env: ManagerBasedRLEnv, command_name: str, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    """
    ç›®æ ‡ä½ç½®è§‚æµ‹ï¼ˆæåæ ‡å½¢å¼ï¼‰

    å¼€å‘åŸºå‡†: Isaac Sim 4.5 + Ubuntu 20.04
    å®˜æ–¹æ–‡æ¡£: https://isaac-sim.github.io/IsaacLab/main/reference/api/isaaclab/mdp/obs.html
    å‚è€ƒç¤ºä¾‹: isaaclab/exts/omni_isaac_lab_tasks/omni/isaac/lab/tasks/locomotion/velocity/observations.py:95

    è®¾è®¡è¯´æ˜:
        - è¿”å›2Då¹³é¢è·ç¦»ï¼ˆå¿½ç•¥Zè½´å·®å¼‚ï¼Œç¬¦åˆå·®é€Ÿæœºå™¨äººç‰¹æ€§ï¼‰
        - è§’åº¦è¯¯å·®å·²å½’ä¸€åŒ–åˆ°[-Ï€, Ï€]
        - æ‰€æœ‰NaN/Infå€¼å·²æ¸…æ´—ï¼ˆé˜²æ­¢è®­ç»ƒå´©æºƒï¼‰

    Args:
        env: ç®¡ç†å™¨åŸºäºRLç¯å¢ƒ
        command_name: å‘½ä»¤ç®¡ç†å™¨ä¸­çš„å‘½ä»¤åç§°ï¼ˆé€šå¸¸ä¸º"target_pose"ï¼‰
        asset_cfg: åœºæ™¯å®ä½“é…ç½®ï¼ˆæŒ‡å®šæœºå™¨äººï¼‰

    Returns:
        torch.Tensor: å½¢çŠ¶ä¸º[num_envs, 2]çš„å¼ é‡
            - [:, 0]: åˆ°ç›®æ ‡çš„è·ç¦»ï¼ˆå•ä½ï¼šç±³ï¼‰
            - [:, 1]: åˆ°ç›®æ ‡çš„æœå‘è¯¯å·®ï¼ˆå•ä½ï¼šå¼§åº¦ï¼ŒèŒƒå›´[-Ï€, Ï€]ï¼‰

    å†å²ä¿®æ”¹:
        - 2024-01-15: æ·»åŠ ä¸¥æ ¼çš„2Dè·ç¦»è®¡ç®—ï¼ˆcommit abc123ï¼‰
        - 2024-01-20: æ·»åŠ NaNæ¸…æ´—ï¼ˆcommit def456ï¼‰
    """
    target_pos_w = env.command_manager.get_command(command_name)[:, :3]
    robot = env.scene[asset_cfg.name]
    
    # ç‰©ç†æ•°æ®å¼ºåŠ›æ¸…æ´—
    robot_pos = torch.nan_to_num(robot.data.root_pos_w, nan=0.0, posinf=0.0, neginf=0.0)
    
    # [æ¶æ„å¸ˆä¿®å¤] ä¸¥æ ¼çš„ 2D è·ç¦»è®¡ç®—ï¼Œå¿½ç•¥ Z è½´å·®å¼‚
    delta_pos_w = target_pos_w[:, :2] - robot_pos[:, :2]
    dist = torch.norm(delta_pos_w, dim=-1, keepdim=True)
    dist = torch.clamp(dist, max=OBSERVATION_CONFIG["max_distance"])  # è·ç¦»æˆªæ–­ï¼ˆé˜²æ­¢æ•°å€¼æº¢å‡ºï¼‰
    
    target_angle = torch.atan2(delta_pos_w[:, 1], delta_pos_w[:, 0])
    _, _, robot_yaw = euler_xyz_from_quat(robot.data.root_quat_w)
    robot_yaw = torch.nan_to_num(robot_yaw, nan=0.0, posinf=0.0, neginf=0.0)
    
    angle_error = wrap_to_pi(target_angle - robot_yaw).unsqueeze(-1)
    
    obs = torch.cat([dist, angle_error], dim=-1)
    return torch.nan_to_num(obs, nan=0.0, posinf=0.0, neginf=0.0)

# =============================================================================
# [æ¶æ„å¸ˆæ–°å¢] æ ¸å¿ƒç‰©ç†è®¡ç®—å·¥å…· (2026-01-25)
# ä½œç”¨ï¼šå°è£… RayCaster è·ç¦»è®¡ç®—é€»è¾‘ï¼Œä¾›è§‚æµ‹å’Œå¥–åŠ±å…±åŒè°ƒç”¨
# =============================================================================

def _compute_raycaster_distance(env: ManagerBasedRLEnv, sensor_cfg: SceneEntityCfg) -> torch.Tensor:
    """
    [v7.0 Core Logic] ä»æ·±åº¦ç›¸æœºè·å–æ¨¡æ‹ŸLiDARæ•°æ®

    å¼€å‘åŸºå‡†: Isaac Sim 4.5 + Ubuntu 20.04
    ä¿®æ”¹åŸå› ï¼šRayCasterå—Warp Meshé™åˆ¶æ— æ³•æ£€æµ‹éšœç¢ç‰©ï¼Œç”¨æ·±åº¦ç›¸æœºæ›¿ä»£

    é€»è¾‘ï¼š
        1. ä»æ·±åº¦ç›¸æœºè·å–æ·±åº¦å›¾ [N, Height, Width] -> [N, 1, 180]
        2. å±•å¹³ä¸º [N, 180] æ¨¡æ‹ŸLiDAR
        3. å¤„ç†æ— æ•ˆå€¼å¹¶é™åˆ¶èŒƒå›´

    è¿”å›ï¼šåŸå§‹è·ç¦»æ•°æ® (å•ä½: ç±³)ï¼Œå½¢çŠ¶ [num_envs, 180]
    """
    # 1. è·å–ä¼ æ„Ÿå™¨
    sensor = env.scene[sensor_cfg.name]

    # 2. ä»æ·±åº¦ç›¸æœºè·å–æ•°æ® [N, Height, Width] -> [N, 1, 180]
    depth_image = sensor.data.output["distance_to_image_plane"]

    # 3. å±•å¹³ä¸º [N, 180] çš„LiDARæ ¼å¼
    ranges = depth_image.squeeze(dim=1)  # ç§»é™¤é«˜åº¦ç»´åº¦

    # 4. å¤„ç†æ— æ•ˆå€¼
    # å°†æ— ç©·å¤§(æ²¡æ‰“åˆ°ç‰©ä½“)æ›¿æ¢ä¸ºæœ€å¤§è·ç¦»
    # å°†è´Ÿå€¼æˆ–NaNè®¾ä¸º0
    max_range = 10.0  # EAI F4 å‚æ•°
    ranges = torch.nan_to_num(ranges, posinf=max_range, neginf=0.0)
    ranges = torch.clamp(ranges, min=0.0, max=max_range)

    return ranges

# =============================================================================
# [æ¶æ„å¸ˆä¿®å¤] å…¼å®¹æ€§è¡¥ä¸ï¼šå¤æ´»æ—§å‡½æ•°å
# ä½œç”¨ï¼šé˜²æ­¢ reward_navigation_sota ç­‰æ—§ä»£ç æŠ¥é”™
# =============================================================================

def _get_corrected_depth(env: ManagerBasedRLEnv, sensor_cfg: SceneEntityCfg) -> torch.Tensor:
    """å…¼å®¹æ—§æ¥å£ï¼Œç›´æ¥è½¬å‘ç»™æ–°çš„è®¡ç®—æ ¸å¿ƒ"""
    return _compute_raycaster_distance(env, sensor_cfg)

# =============================================================================
# è§‚æµ‹å¤„ç†å‡½æ•°
# =============================================================================

def process_lidar_ranges(env: ManagerBasedRLEnv, sensor_cfg: SceneEntityCfg) -> torch.Tensor:
    """
    [v7.0 é€‚é…] å¤„ç†æ·±åº¦ç›¸æœºæ¨¡æ‹Ÿçš„LiDARæ•°æ®

    å¼€å‘åŸºå‡†: Isaac Sim 4.5 + Ubuntu 20.04

    æ•°æ®æµï¼š
        1. æ·±åº¦ç›¸æœº [N, 1, 180] (height=1, width=180)
        2. å±•å¹³ä¸º [N, 180]
        3. å½’ä¸€åŒ–åˆ° [0, 1]
        4. é™é‡‡æ ·åˆ°90ä¸ªæ‰‡åŒº (æ¯2Â°ä¸€ä¸ªæ‰‡åŒº)

    Returns:
        torch.Tensor: å½¢çŠ¶ä¸º [num_envs, 90] çš„å½’ä¸€åŒ–è·ç¦»æ•°ç»„
    """
    # 1. è°ƒç”¨æ ¸å¿ƒå·¥å…·è·å–ç±³åˆ¶è·ç¦» [N, 180]
    distances = _compute_raycaster_distance(env, sensor_cfg)

    # 2. å½’ä¸€åŒ–åˆ° [0, 1]
    max_range = 10.0
    distances_normalized = distances / max_range

    # 3. é™é‡‡æ ·åˆ°90ä¸ªæ‰‡åŒº (æ¯2Â°ä¸€ä¸ªï¼Œä»180Â°é™åˆ°90Â°)
    num_sectors = 90
    batch_size, num_rays = distances_normalized.shape

    if num_rays % num_sectors == 0:
        # æ¯ä¸ªæ‰‡åŒºå–æœ€å°å€¼ï¼ˆæœ€å®‰å…¨çš„éšœç¢ç‰©è·ç¦»ï¼‰
        depth_sectors = distances_normalized.view(batch_size, num_sectors, -1).min(dim=2)[0]
    else:
        # å¦‚æœä¸èƒ½æ•´é™¤ï¼Œä¿æŒåŸæ ·
        depth_sectors = distances_normalized

    return depth_sectors


# ============================================================================
# [Geo-Distill V2.2] 4å‘æ·±åº¦ç›¸æœºæ‹¼æ¥å¤„ç†å‡½æ•°
# ============================================================================

def process_stitched_lidar(env: ManagerBasedRLEnv) -> torch.Tensor:
    """
    [Geo-Distill V2.2] 4å‘æ·±åº¦ç›¸æœºæ‹¼æ¥ + é™é‡‡æ · (360 â†’ 72)

    å¼€å‘åŸºå‡†: Isaac Sim 4.5 + Ubuntu 20.04
    ä¿®å¤åŸå› ï¼šå•ç›¸æœºæ— æ³•å®ç°360Â° FOVï¼Œä½¿ç”¨4ä¸ª90Â°ç›¸æœºæ‹¼æ¥

    æ•°æ®æµï¼š
        1. è·å–4ä¸ªç›¸æœºæ·±åº¦æ•°æ® [N, 90] each
        2. æ‹¼æ¥æˆ360åº¦å…¨æ™¯ (é€†æ—¶é’ˆï¼šFrontâ†’Leftâ†’Backâ†’Right)
        3. é™é‡‡æ ·åˆ°72ç‚¹ (æ¯5Â°ä¸€ä¸ªç‚¹)
        4. å½’ä¸€åŒ–åˆ° [0, 1]

    Returns:
        torch.Tensor: å½¢çŠ¶ä¸º [num_envs, 72] çš„å½’ä¸€åŒ–LiDARæ•°æ®

    å¯¹é½å®ç‰©ï¼šEAI F4 LiDAR (360Â°æ‰«æã€5-12mèŒƒå›´ã€5-10Hzé¢‘ç‡)
    """
    # 1. è·å–4ä¸ªç›¸æœºçš„æ·±åº¦æ•°æ®
    # [Fix 2026-01-27] Isaac Lab ç›¸æœºæ•°æ®å­˜å‚¨åœ¨ .data.output å­—å…¸ä¸­
    # æ¶æ„å¸ˆè¯Šæ–­ï¼šCameraData å°†æ‰€æœ‰è¯·æ±‚çš„æ•°æ®ç±»å‹å­˜å‚¨åœ¨ output å­—å…¸ä¸­
    d_front = env.scene["camera_front"].data.output["distance_to_image_plane"]  # [N, 1, 90]
    d_left = env.scene["camera_left"].data.output["distance_to_image_plane"]    # [N, 1, 90]
    d_back = env.scene["camera_back"].data.output["distance_to_image_plane"]    # [N, 1, 90]
    d_right = env.scene["camera_right"].data.output["distance_to_image_plane"]  # [N, 1, 90]

    # 2. å‹ç¼©ç»´åº¦ [N, 1, 90] â†’ [N, 90]
    scan_front = d_front.squeeze(1)
    scan_left = d_left.squeeze(1)
    scan_back = d_back.squeeze(1)
    scan_right = d_right.squeeze(1)

    # 3. æ‹¼æ¥æˆ360åº¦ (é€†æ—¶é’ˆï¼šFrontâ†’Leftâ†’Backâ†’Right)
    #    å¯¹é½å®è½¦EAI F4é›·è¾¾çš„é€†æ—¶é’ˆæ‰«ææ–¹å‘
    full_scan = torch.cat([scan_front, scan_left, scan_back, scan_right], dim=1)  # [N, 360]

    # 4. å¤„ç†æ— æ•ˆå€¼
    max_range = 12.0  # EAI F4 æœ€å¤§è·ç¦»
    full_scan = torch.nan_to_num(full_scan, posinf=max_range, neginf=0.0)
    full_scan = torch.clamp(full_scan, min=0.0, max=max_range)

    # 5. é™é‡‡æ · 360 â†’ 72 (Min-Poolingä¿ç•™æ¯ç»„æœ€å°è·ç¦»)
    # [Phase 1.1ä¿®å¤] æ¶æ„å¸ˆå®¡è®¡å‘ç°Max-Poolingå¯¼è‡´42.8%æ¼æ£€ç‡
    # åŸç†ï¼šæ¯5ä¸ªè¿ç»­ç‚¹å–æœ€å°å€¼ï¼Œä¿ç•™æœ€è¿‘éšœç¢ç‰©ä¿¡æ¯
    # ä¿®å¤ï¼štorch.max â†’ torch.min (2026-01-31)
    # æ•°å­¦ï¼šLiDARæ•°æ®å€¼å°=éšœç¢ç‰©è¿‘(å±é™©)ï¼Œå€¼å¤§=ç©ºæ—·(å®‰å…¨)
    #      min([0.5, 2.0, 3.5, 4.0, 2.5]) = 0.5m âœ… ä¿ç•™å±é™©ä¿¡æ¯
    #      max([0.5, 2.0, 3.5, 4.0, 2.5]) = 4.0m âŒ å¿½ç•¥éšœç¢ç‰©
    N = full_scan.shape[0]
    full_scan_reshaped = full_scan.reshape(N, 4, 90)  # [N, 4, 90] = 360ç‚¹åˆ†ç»„
    full_scan_reshaped = full_scan_reshaped.reshape(N, 4, 18, 5)  # [N, 4, 18, 5] æ¯ç»„5ç‚¹
    downsampled, _ = torch.min(full_scan_reshaped, dim=3)  # [N, 4, 18] å–æœ€å°å€¼ âœ…
    downsampled = downsampled.reshape(N, 72)  # [N, 72] å±•å¹³ä¸º72ç»´

    # 6. å½’ä¸€åŒ–åˆ° [0, 1]
    return downsampled / max_range

# ============================================================================
# [v8.0] ä¸šç•Œæ ‡å‡†é¿éšœç­–ç•¥ - é€Ÿåº¦-è·ç¦»åŠ¨æ€çº¦æŸ
# ============================================================================

def penalty_unsafe_speed(env: ManagerBasedRLEnv, asset_cfg: SceneEntityCfg, min_dist_threshold: float = 0.25) -> torch.Tensor:
    """
    [v8.1 ä¿®å¤ç‰ˆ] é€Ÿåº¦-è·ç¦» åŠ¨æ€çº¦æŸ

    ä¿®å¤ï¼šå…ˆå±•å¹³æ‰€æœ‰ç›¸æœºæ•°æ®ï¼Œç¡®ä¿ min_dist æ˜¯ [N] å½¢çŠ¶ï¼Œè€Œä¸æ˜¯ [N, W]

    æ ¸å¿ƒé€»è¾‘ï¼š"ç¦»å¾—è¿‘æ²¡å…³ç³»ï¼Œä½†ç¦»å¾—è¿‘è¿˜**è·‘å¾—å¿«**ï¼Œå°±æ˜¯æ‰¾æ­»ã€‚"

    æ•°å­¦å…¬å¼ï¼š
        safe_vel_limit = clamp(min_dist, max=0.5)
        overspeed = clamp(vel - safe_vel_limit, min=0.0)
        penalty = -overspeed

    Args:
        env: ç¯å¢ƒå¯¹è±¡
        asset_cfg: æœºå™¨äººé…ç½®
        min_dist_threshold: æœ€å°å®‰å…¨è·ç¦»ï¼ˆé»˜è®¤0.25mï¼‰

    Returns:
        torch.Tensor: è¶…é€Ÿæƒ©ç½š [N]

    æ¶æ„å¸ˆ: Isaac Sim Architect (2026-01-27)
    å‚è€ƒæ–¹æ¡ˆ: ETH Zurich RSL-RL, OpenAI Navigation, ROS2 Nav2
    """
    # 1. è·å–æ‰€æœ‰ç›¸æœºæ•°æ® [N, H, W]
    # æ³¨æ„ï¼šä½¿ç”¨ .data.output[...] è·å–æ¸²æŸ“æ•°æ®
    d_front = env.scene["camera_front"].data.output["distance_to_image_plane"]
    d_left = env.scene["camera_left"].data.output["distance_to_image_plane"]
    d_back = env.scene["camera_back"].data.output["distance_to_image_plane"]
    d_right = env.scene["camera_right"].data.output["distance_to_image_plane"]

    # 2. æ‹¼æ¥å¹¶å±•å¹³
    # [N, H, W] -> [N, 4*H*W]
    batch_size = d_front.shape[0]
    all_pixels = torch.cat([d_front, d_left, d_back, d_right], dim=1).view(batch_size, -1)

    # 3. è·å–å…¨åœºæœ€è¿‘è·ç¦» [N]
    # è¿‡æ»¤ inf (æœªæ¢æµ‹åˆ°) ä¸ºæœ€å¤§è·ç¦»ï¼Œé¿å… min å–åˆ° inf å¯¼è‡´é€»è¾‘é”™è¯¯
    all_pixels = torch.nan_to_num(all_pixels, posinf=12.0)
    min_dist = torch.min(all_pixels, dim=1)[0]

    # 4. è·å–å½“å‰é€Ÿåº¦ [N]
    vel = env.scene[asset_cfg.name].data.root_lin_vel_b[:, 0]

    # 5. è®¡ç®—æƒ©ç½š
    # è·ç¦» < 0.25m æ—¶ï¼Œé™åˆ¶æœ€å¤§é€Ÿåº¦
    # 0.25m -> é™é€Ÿ 0.25m/s
    # 0.10m -> é™é€Ÿ 0.10m/s
    safe_vel_limit = torch.clamp(min_dist, max=0.5)

    # è®¡ç®—è¶…é€Ÿé‡ (åªæœ‰ > 0 æ‰æƒ©ç½š)
    overspeed = torch.clamp(vel - safe_vel_limit, min=0.0)

    return -overspeed


def penalty_undesired_contacts(env: ManagerBasedRLEnv, sensor_cfg: SceneEntityCfg, threshold: float = 0.1) -> torch.Tensor:
    """
    [v8.0] è½»å¾®æ¥è§¦æƒ©ç½š - ç¬¬äºŒå±‚é˜²å¾¡

    æ ¸å¿ƒé€»è¾‘ï¼šåªè¦ç¢°åˆ°ä»»ä½•ä¸œè¥¿ï¼ˆåŠ› > 0.1Nï¼‰ï¼Œå°±æ¯å¸§æ‰£åˆ†

    è®¾è®¡ç†å¿µï¼š
        - ç¬¬ä¸€å±‚ï¼ˆTerminationï¼‰ï¼šçŒ›çƒˆç¢°æ’ï¼ˆ>50Nï¼‰ç›´æ¥é‡ç½®
        - ç¬¬äºŒå±‚ï¼ˆRewardï¼‰ï¼šè½»å¾®æ¥è§¦ï¼ˆ0.1Nï¼‰ç»™äºˆç–¼ç—›æ„Ÿï¼Œä½†ä¸é‡ç½®
        - ç›®çš„ï¼šè®©æœºå™¨äººå­¦ä¼š"åˆ«ç¢°æˆ‘"ï¼Œä½†ä¸ä¼šå› ä¸ºè½»è½»è¹­ä¸€ä¸‹å°±æ­»

    Args:
        env: ç¯å¢ƒå¯¹è±¡
        sensor_cfg: æ¥è§¦åŠ›ä¼ æ„Ÿå™¨é…ç½®
        threshold: æ¥è§¦åŠ›é˜ˆå€¼ï¼ˆé»˜è®¤0.1Nï¼Œæä½çš„é˜ˆå€¼ï¼‰

    Returns:
        torch.Tensor: æ¥è§¦æƒ©ç½š [N]

    æ¶æ„å¸ˆ: Isaac Sim Architect (2026-01-27)
    """
    # [Fix 2026-01-27] ä½¿ç”¨æ­£ç¡®çš„å±æ€§å net_forces_w
    # Isaac Lab ContactSensor çš„å±æ€§åæ˜¯ net_forces_wï¼Œè€Œé net_contact_forces
    # data.net_forces_w çš„å½¢çŠ¶æ˜¯ [num_envs, num_bodies, 3]
    contact_data = env.scene[sensor_cfg.name].data.net_forces_w  # [N, num_bodies, 3]

    # [Fix 2026-01-27] è®¡ç®—åˆåŠ›å¤§å°å¹¶é™ç»´
    # å…ˆè®¡ç®—åŠ›çš„æ¨¡é•¿ -> [N, num_bodies]
    # ç„¶åå–æœ€å¤§å€¼ï¼ˆå‡è®¾åº•ç›˜æœ‰å¤šä¸ªç¢°æ’ä½“ï¼Œå–å—åŠ›æœ€å¤§çš„é‚£ä¸ªï¼‰-> [N]
    force_mag = torch.norm(contact_data, dim=-1).max(dim=1)[0]  # [N]

    # ä»»ä½•è¶…è¿‡é˜ˆå€¼çš„æ¥è§¦éƒ½ç»™äºˆæƒ©ç½š
    has_contact = force_mag > threshold

    # è¿”å›æƒ©ç½šï¼ˆè½»å¾®æ‰£åˆ†ï¼Œæƒé‡ç”± RewardsCfg æ§åˆ¶ï¼‰
    return -torch.where(has_contact, 1.0, 0.0)


# =============================================================================
# [v5.1 ACL] è‡ªé€‚åº”è¯¾ç¨‹å­¦ä¹ æ ¸å¿ƒå‡½æ•°
# =============================================================================

def curriculum_adaptive_distance(env, env_ids, command_name,
                                initial_dist, max_dist, step_size,
                                upgrade_threshold, downgrade_threshold,
                                window_size):
    """
    [v5.2 Fix] è‡ªé€‚åº”è¯¾ç¨‹å‡½æ•° (ä¿®å¤ Crash + å®è£…éš¾åº¦åº”ç”¨)

    Fix:
    1. è¿”å›å€¼æ”¹ä¸ºæ ‡é‡ Tensor (è§£å†³ RuntimeError)
    2. å¢åŠ äº†å¯¹ Command Manager çš„å®é™…ä¿®æ”¹ï¼Œç¡®ä¿éš¾åº¦ç”Ÿæ•ˆ
    """
    # 1. åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®
    if not hasattr(env, "curriculum_stats"):
        env.curriculum_stats = {
            "current_dist": initial_dist,
            "window_size": window_size
        }
        # åˆå§‹è¿”å›æ ‡é‡
        return torch.tensor(env.curriculum_stats["current_dist"], device=env.device)

    # 2. å®‰å…¨æ£€æŸ¥: ç­‰å¾… metrics æ•°æ®å°±ç»ª
    is_startup = not env.extras or "log" not in env.extras or "success" not in env.extras["log"]

    if not is_startup:
        # è·å–æˆåŠŸçŠ¶æ€
        successes = env.extras["log"]["success"][env_ids].float()

        if len(successes) > 0:
            batch_success_rate = torch.mean(successes)

            # åŠ¨æ€è°ƒæ•´é€»è¾‘
            stats = env.curriculum_stats
            current_dist = stats["current_dist"]

            # å‡çº§/é™çº§é€»è¾‘
            if batch_success_rate > upgrade_threshold:
                current_dist = min(current_dist + step_size, max_dist)
            elif batch_success_rate < downgrade_threshold:
                current_dist = max(current_dist - step_size, initial_dist)

            stats["current_dist"] = current_dist
            env.curriculum_stats = stats

            # -------------------------------------------------------
            # ğŸ”¥ æ ¸å¿ƒå¢å¼º: å®é™…ä¿®æ”¹å‘½ä»¤ç”Ÿæˆå™¨çš„èŒƒå›´ (Side Effect)
            # -------------------------------------------------------
            try:
                # è·å– target_pose å‘½ä»¤é¡¹ (æ ¹æ®æ—¥å¿—ä¸­çš„åå­—)
                cmd_term = env.command_manager.get_term("target_pose")

                # ä¿®æ”¹ç”ŸæˆèŒƒå›´ (é€‚é… RelativeRandomTargetCommand)
                # å°è¯•ä¿®æ”¹æåæ ‡åŠå¾„ (r)
                if hasattr(cmd_term.cfg.ranges, "r"):
                    # èŒƒå›´è®¾ä¸º [1.5, current_dist] æˆ–è€… [current_dist, current_dist]
                    # é€šå¸¸ curriculum æ˜¯æ‰©å¤§èŒƒå›´ä¸Šé™
                    cmd_term.cfg.ranges.r = (term_cfg.params["initial_dist"], current_dist)

                # å¤‡ç”¨: å¦‚æœæ˜¯ç¬›å¡å°”åæ ‡ (pos_x, pos_y)
                elif hasattr(cmd_term.cfg.ranges, "pos_x"):
                    half_dist = current_dist
                    cmd_term.cfg.ranges.pos_x = (-half_dist, half_dist)
                    cmd_term.cfg.ranges.pos_y = (-half_dist, half_dist)

            except Exception as e:
                # ä»…åœ¨ç¬¬ä¸€æ¬¡å¤±è´¥æ—¶æ‰“å°ï¼Œé˜²æ­¢åˆ·å±
                if not hasattr(env, "cmd_update_error_logged"):
                    print(f"[Warning] Failed to update command range: {e}")
                    env.cmd_update_error_logged = True

    # 3. è¿”å›å½“å‰éš¾åº¦ (æ ‡é‡!)
    # ä¿®å¤äº†ä¹‹å‰è¿”å› vector å¯¼è‡´çš„ RuntimeError
    current_dist = env.curriculum_stats["current_dist"]
    return torch.tensor(current_dist, device=env.device)

# =============================================================================
# [v5.0 Legacy] çº¿æ€§è¯¾ç¨‹å­¦ä¹ ï¼ˆä¿ç•™ç”¨äºå¯¹æ¯”ï¼‰
# =============================================================================

def curriculum_expand_target_range(env, env_ids, command_name, start_step, end_step, min_limit, max_limit):
    """
    [v5.0 æ ¸å¿ƒ] è‡ªåŠ¨åŒ–è¯¾ç¨‹å­¦ä¹ 
    æ ¹æ®å½“å‰è®­ç»ƒæ€»æ­¥æ•°ï¼Œçº¿æ€§æ‰©å±•ç›®æ ‡ç”Ÿæˆçš„è·ç¦»èŒƒå›´ (3m -> 8m)

    å¼€å‘åŸºå‡†: Isaac Sim 4.5 + Ubuntu 20.04
    å®˜æ–¹æ–‡æ¡£: https://isaac-sim.github.io/IsaacLab/main/reference/api/isaaclab/managers.html
    å‚è€ƒç¤ºä¾‹: Isaac Labå®˜æ–¹curriculumå­¦ä¹ ç¤ºä¾‹

    åŸç†ï¼š
        - é€šè¿‡åŠ¨æ€ä¿®æ”¹å‘½ä»¤ç”Ÿæˆå™¨çš„é…ç½®èŒƒå›´å®ç°éš¾åº¦çˆ¬å¡
        - ä½¿ç”¨ç‰©ç†æ­¥æ•°ï¼ˆcommon_step_counterï¼‰è€Œéiterationæ•°ä½œä¸ºæ—¶é—´åŸºå‡†
        - çº¿æ€§æ’å€¼ä¿è¯å¹³æ»‘è¿‡æ¸¡

    Args:
        env: ç®¡ç†å‹RLç¯å¢ƒ
        env_ids: æœ¬æ¬¡é‡ç½®çš„ç¯å¢ƒIDï¼ˆæœªä½¿ç”¨ï¼Œä¿æŒæ¥å£ä¸€è‡´ï¼‰
        command_name: è¦ä¿®æ”¹çš„å‘½ä»¤åç§°ï¼ˆ"target_pose"ï¼‰
        start_step: è¯¾ç¨‹å¼€å§‹æ­¥æ•°ï¼ˆç‰©ç†æ­¥ï¼‰
        end_step: è¯¾ç¨‹ç»“æŸæ­¥æ•°ï¼ˆç‰©ç†æ­¥ï¼‰
        min_limit: åˆå§‹è·ç¦»é™åˆ¶ï¼ˆ3.0mï¼‰
        max_limit: æœ€ç»ˆè·ç¦»é™åˆ¶ï¼ˆ8.0mï¼‰
    """
    current_step = env.common_step_counter

    # è®¡ç®—è¿›åº¦ alpha (0.0 ~ 1.0)
    if current_step < start_step:
        alpha = 0.0
    elif current_step > end_step:
        alpha = 1.0
    else:
        alpha = (current_step - start_step) / (end_step - start_step)

    # è®¡ç®—å½“å‰éš¾åº¦
    current_limit = min_limit + (max_limit - min_limit) * alpha

    # åŠ¨æ€ä¿®æ”¹å‘½ä»¤ç”Ÿæˆå™¨çš„å‚æ•°
    cmd_term = env.command_manager.get_term(command_name)
    if hasattr(cmd_term.cfg, "ranges") and hasattr(cmd_term.cfg.ranges, "pos_x"):
        # åŒæ—¶ä¿®æ”¹ X å’Œ Y çš„èŒƒå›´ï¼Œä¿æŒæ­£æ–¹å½¢åŒºåŸŸ
        cmd_term.cfg.ranges.pos_x = (-current_limit, current_limit)
        cmd_term.cfg.ranges.pos_y = (-current_limit, current_limit)

# =============================================================================
# [v5.0 Hotfix] è‡ªå®šä¹‰tanhè·ç¦»å¥–åŠ±å‡½æ•°
# =============================================================================

def reward_position_command_error_tanh(env, std: float, command_name: str, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    """
    [v5.0 Hotfix] æ‰‹åŠ¨å®ç°tanhè·ç¦»å¥–åŠ±ï¼ˆIsaac Lab 4.5æ— æ­¤APIï¼‰

    å¼€å‘åŸºå‡†: Isaac Sim 4.5 + Ubuntu 20.04
    é—®é¢˜ä¿®å¤: AttributeError: module 'isaaclab.envs.mdp.rewards' has no attribute 'position_command_error_tanh'

    å¥–åŠ±èŒƒå›´: (0, 1]
    é€»è¾‘: è·ç¦»è¶Šè¿‘ï¼Œå¥–åŠ±è¶Šé«˜ï¼ˆæ¥è¿‘1ï¼‰ï¼›è·ç¦»è¶Šè¿œï¼Œå¥–åŠ±è¶Šä½ï¼ˆæ¥è¿‘0ï¼‰

    æ•°å­¦åŸç†:
        reward = 1.0 - tanh(dist / std)
        - å½“ dist = 0, tanh = 0, reward = 1.0ï¼ˆåˆ°è¾¾ç›®æ ‡ï¼‰
        - å½“ dist = std, tanh â‰ˆ 0.76, reward â‰ˆ 0.24ï¼ˆä¸­ç­‰è·ç¦»ï¼‰
        - å½“ dist >> std, tanh â‰ˆ 1.0, reward â‰ˆ 0.0ï¼ˆè¿œè·ç¦»ï¼‰

    Args:
        env: ç®¡ç†å‹RLç¯å¢ƒ
        std: æ ‡å‡†åŒ–å‚æ•°ï¼Œæ§åˆ¶tanhé¥±å’Œé€Ÿåº¦
        command_name: å‘½ä»¤åç§°ï¼ˆ"target_pose"ï¼‰
        asset_cfg: æœºå™¨äººå®ä½“é…ç½®

    Returns:
        torch.Tensor: å½¢çŠ¶ä¸º[num_envs]çš„å¥–åŠ±å¼ é‡ï¼ŒèŒƒå›´(0, 1]
    """
    # 1. è·å–ç›®æ ‡ä½ç½® (x, y)
    target_pos = env.command_manager.get_command(command_name)[:, :2]

    # 2. è·å–æœºå™¨äººä½ç½® (x, y)
    robot_pos = env.scene[asset_cfg.name].data.root_pos_w[:, :2]

    # 3. è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»
    dist = torch.norm(target_pos - robot_pos, dim=1)

    # 4. è®¡ç®—tanhå¥–åŠ±
    return 1.0 - torch.tanh(dist / std)

# =============================================================================
# [v5.0 Ultimate] è¾…åŠ©å¥–åŠ±å‡½æ•°
# =============================================================================

def reward_target_speed(env, asset_cfg):
    """
    [Geo-Distill V3.0] é€Ÿåº¦å¥–åŠ±ï¼šä¸‰é‡ä¿æŠ¤æœºåˆ¶

    å¼€å‘åŸºå‡†: Isaac Sim 4.5 + Ubuntu 20.04
    ä¿®å¤åŸå› ï¼š
        1. é˜²æ­¢"å€’è½¦åˆ·åˆ†"å¯¼è‡´é†‰æ±‰èµ°è·¯
        2. é˜²æ­¢"åŸåœ°è½¬åœˆ"ï¼ˆangular_penaltyï¼‰
        3. å€’è½¦æƒ©ç½šå¤ªå¼±ï¼ˆ-2.0 â†’ -10.0ï¼‰

    å¥–åŠ±é€»è¾‘ï¼š
        - å‰è¿›ï¼ˆvel > 0ï¼‰ï¼šæŒ‡æ•°å¥–åŠ±ï¼ˆé¼“åŠ±æ¥è¿‘0.3 m/sï¼‰
        - å€’è½¦ï¼ˆvel < 0ï¼‰ï¼š5å€æƒ©ç½šï¼ˆä»2å€æé«˜åˆ°5å€ï¼‰
        - æ—‹è½¬ï¼ˆang_velï¼‰ï¼š-0.5 * abs(ang_vel) æ–°å¢

    [2026-01-27] è°ƒæ•´ç›®æ ‡é€Ÿåº¦ï¼š0.25 â†’ 0.3 m/s
    [V3.0] æ·»åŠ è§’é€Ÿåº¦æƒ©ç½šï¼Œé˜²æ­¢è½¬åœˆ
    """
    vel = env.scene[asset_cfg.name].data.root_lin_vel_b[:, 0]
    ang_vel = env.scene[asset_cfg.name].data.root_ang_vel_b[:, 2]  # âœ… V3.0: æ–°å¢
    target_vel = 0.3  # [2026-01-27] è°ƒæ•´ä¸º0.3 m/s

    # å‰è¿›ï¼šæŒ‡æ•°å¥–åŠ±
    forward_reward = torch.exp(-torch.abs(vel - target_vel) / 0.1)

    # å€’è½¦ï¼š5å€æƒ©ç½šï¼ˆä»2å€æé«˜åˆ°5å€ï¼‰
    backward_penalty = torch.where(vel < 0, -10.0 * torch.abs(vel), 0.0)

    # âœ… [V3.0] è§’é€Ÿåº¦æƒ©ç½šï¼ˆæŠ‘åˆ¶è½¬åœˆï¼‰
    angular_penalty = -REWARD_CONFIG["angular_penalty"] * torch.abs(ang_vel)

    return forward_reward + backward_penalty + angular_penalty

def reward_facing_target(env, command_name, asset_cfg):
    """
    [v5.0] å¯¹å‡†å¥–åŠ±ï¼šé¼“åŠ±è½¦å¤´æœå‘ç›®æ ‡
    """
    target_pos = env.command_manager.get_command(command_name)[:, :2]
    robot_pos = env.scene[asset_cfg.name].data.root_pos_w[:, :2]
    robot_yaw = env.scene[asset_cfg.name].data.heading_w
    target_vec = target_pos - robot_pos
    target_yaw = torch.atan2(target_vec[:, 1], target_vec[:, 0])
    angle_error = torch.abs(mdp.math.wrap_to_pi(target_yaw - robot_yaw))
    return 1.0 / (1.0 + angle_error)

# =============================================================================
# 3. å¥–åŠ±å‡½æ•° (åŒ…å« Goal Fixing å’Œ NaN æ¸…æ´—)
# =============================================================================

def reward_navigation_sota(env: ManagerBasedRLEnv, asset_cfg: SceneEntityCfg, sensor_cfg: SceneEntityCfg, command_name: str) -> torch.Tensor:
    """
    SOTAé£æ ¼å¯¼èˆªå¥–åŠ±å‡½æ•°

    å¼€å‘åŸºå‡†: Isaac Sim 4.5 + Ubuntu 20.04
    å®˜æ–¹æ–‡æ¡£: https://isaac-sim.github.io/IsaacLab/main/reference/api/isaaclab/mdp/rewards.html
    å‚è€ƒç¤ºä¾‹: isaaclab/exts/omni_isaac_lab_tasks/omni/isaac/lab/tasks/locomotion/velocity/rewards.py:120

    å¥–åŠ±é¡¹ç»„æˆ:
        1. è¿›åº¦å¥–åŠ±: forward_vel * cos(angle_error) - é¼“åŠ±å‘ç›®æ ‡å‰è¿›
        2. æé€Ÿå¥–åŠ±: é€Ÿåº¦>0.25ä¸”æœå‘æ­£ç¡®æ—¶ç»™äºˆ - é¼“åŠ±å¿«é€Ÿå‰è¿›
        3. å€’è½¦æƒ©ç½š: æƒ©ç½šå€’è½¦è¡Œä¸º
        4. é¿éšœæƒ©ç½š: åŸºäºLiDARè·ç¦»çš„æŒ‡æ•°æƒ©ç½š

    è®¾è®¡ä¾æ®:
        - è¿›åº¦å¥–åŠ±: åŠ¿èƒ½å·®å¥–åŠ±çš„ç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…è¿‡åº¦ä¼˜åŒ–
        - æé€Ÿå¥–åŠ±: é¼“åŠ±æœºå™¨äººä½¿ç”¨æ¥è¿‘max_vel_xçš„é€Ÿåº¦ï¼ˆ0.25 vs 0.3ï¼‰
        - é¿éšœé˜ˆå€¼: 0.55mï¼ˆçº¦2.7å€robot_radiusï¼‰ï¼Œç¬¦åˆROSå®‰å…¨è·ç¦»

    Args:
        env: ç®¡ç†å™¨åŸºäºRLç¯å¢ƒ
        asset_cfg: æœºå™¨äººå®ä½“é…ç½®
        sensor_cfg: LiDARä¼ æ„Ÿå™¨é…ç½®
        command_name: ç›®æ ‡å‘½ä»¤åç§°

    Returns:
        torch.Tensor: å½¢çŠ¶ä¸º[num_envs]çš„å¥–åŠ±å¼ é‡ï¼ŒèŒƒå›´å·²è£å‰ªåˆ°[-10, 10]

    å†å²ä¿®æ”¹:
        - 2024-01-20: é™ä½å¹³æ»‘åº¦æƒ©ç½šæƒé‡ï¼ˆcommit 123abcï¼‰
        - 2024-01-22: æ·»åŠ æé€Ÿå¥–åŠ±é¡¹ï¼ˆcommit 456defï¼‰
    """
    robot = env.scene[asset_cfg.name]
    target_pos_w = env.command_manager.get_command(command_name)[:, :3]

    # åŸºç¡€æ•°æ®æ¸…æ´—
    forward_vel = torch.nan_to_num(robot.data.root_lin_vel_b[:, 0], nan=0.0, posinf=0.0, neginf=0.0)
    # âœ… [V3.0] æ¢å¤ang_velæƒ©ç½šï¼ˆä¹‹å‰æ³¨é‡Šæ‰å¯¼è‡´è½¬åœˆé—®é¢˜ï¼‰
    ang_vel = torch.nan_to_num(robot.data.root_ang_vel_b[:, 2], nan=0.0, posinf=0.0, neginf=0.0)

    forward_vel = torch.clamp(forward_vel, -10.0, 10.0)
    
    robot_pos = torch.nan_to_num(robot.data.root_pos_w, nan=0.0, posinf=0.0, neginf=0.0)
    
    # [æ¶æ„å¸ˆä¿®å¤] ä¸¥æ ¼ 2D è®¡ç®—
    delta_pos_w = target_pos_w[:, :2] - robot_pos[:, :2]
    
    target_angle = torch.atan2(delta_pos_w[:, 1], delta_pos_w[:, 0])
    _, _, robot_yaw = euler_xyz_from_quat(robot.data.root_quat_w)
    robot_yaw = torch.nan_to_num(robot_yaw, nan=0.0, posinf=0.0, neginf=0.0)
    angle_error = wrap_to_pi(target_angle - robot_yaw)
    
    # [1] è¿›åº¦å¥–åŠ±
    reward_progress = REWARD_CONFIG["progress_weight"] * forward_vel * torch.cos(angle_error)

    # [2] æé€Ÿå¥–åŠ±
    is_facing_target = torch.cos(angle_error) > REWARD_CONFIG["facing_threshold"]
    reward_high_speed = (
        (forward_vel > REWARD_CONFIG["high_speed_threshold"]).float() *
        is_facing_target.float() *
        REWARD_CONFIG["high_speed_reward"]
    )

    # [3] å€’è½¦æƒ©ç½š
    reward_backward = -REWARD_CONFIG["backward_penalty"] * torch.abs(
        torch.min(forward_vel, torch.zeros_like(forward_vel))
    )

    # [4] é¿éšœæƒ©ç½š
    # [å…¼å®¹] headless æ¨¡å¼ä¸‹ä¼ æ„Ÿå™¨ä¸å­˜åœ¨ï¼Œè·³è¿‡é¿éšœæƒ©ç½š
    if sensor_cfg is not None:
        depth_radial = _get_corrected_depth(env, sensor_cfg)
        min_dist = torch.min(depth_radial, dim=-1)[0]
        safe_dist = REWARD_CONFIG["safe_distance"]
        reward_collision = torch.zeros_like(min_dist)
        mask_danger = min_dist < safe_dist
        reward_collision[mask_danger] = -REWARD_CONFIG["collision_penalty"] * torch.exp(
            REWARD_CONFIG["collision_decay"] * (safe_dist - min_dist[mask_danger])
        )
    else:
        # headless æ¨¡å¼ï¼šæ²¡æœ‰ä¼ æ„Ÿå™¨æ•°æ®ï¼Œä½¿ç”¨é›¶é¿éšœæƒ©ç½š
        reward_collision = torch.zeros(forward_vel.shape, device=env.device)

    # [5] åŠ¨ä½œå¹³æ»‘ (ç§»é™¤ï¼Œæ”¹ä¸ºå•ç‹¬é¡¹å¹¶é™ä½æƒé‡)
    # reward_rot = -0.05 * torch.abs(ang_vel)**2

    # âœ… [V3.0] è§’é€Ÿåº¦æƒ©ç½šï¼ˆé˜²æ­¢è½¬åœˆï¼‰
    reward_angular = -REWARD_CONFIG["angular_penalty"] * torch.abs(ang_vel)

    # âœ… [V3.0] åœè½¦è¯±å¯¼é€»è¾‘ï¼ˆåŠ¿èƒ½äº•ï¼‰
    # åªæœ‰åŒæ—¶æ»¡è¶³ dist<0.25 AND vel<0.1 æ‰ç»™100åˆ†
    is_at_goal = torch.norm(delta_pos_w, p=2, dim=-1) < REWARD_CONFIG["stop_dist_thresh"]
    is_stopped = torch.abs(forward_vel) < REWARD_CONFIG["stop_vel_thresh"]
    reward_terminal = torch.where(
        is_at_goal & is_stopped,
        torch.tensor(REWARD_CONFIG["terminal_reward"], device=env.device),
        torch.tensor(0.0, device=env.device)
    )

    total_reward = (reward_progress + reward_high_speed + reward_backward +
                   reward_collision + reward_angular + reward_terminal)
    return torch.clamp(
        torch.nan_to_num(total_reward, nan=0.0, posinf=0.0, neginf=0.0),
        REWARD_CONFIG["reward_clip_min"],
        REWARD_CONFIG["reward_clip_max"]
    )

# [æ¶æ„å¸ˆé‡æ„] åŸºäºåŠ¿èƒ½å·®çš„å¼•å¯¼å¥–åŠ±
def reward_distance_tracking_potential(env: ManagerBasedRLEnv, command_name: str, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    target_pos = env.command_manager.get_command(command_name)[:, :2]
    robot_pos = torch.nan_to_num(env.scene[asset_cfg.name].data.root_pos_w[:, :2], nan=0.0, posinf=0.0, neginf=0.0)
    current_dist = torch.norm(target_pos - robot_pos, dim=-1)
    
    delta_pos = target_pos - robot_pos
    dist_vec = delta_pos / (current_dist.unsqueeze(-1) + OBSERVATION_CONFIG["epsilon"])  # é˜²æ­¢é™¤é›¶ 
    lin_vel_w = env.scene[asset_cfg.name].data.root_lin_vel_w[:, :2]
    lin_vel_w = torch.nan_to_num(lin_vel_w, nan=0.0, posinf=0.0, neginf=0.0)
    
    approach_velocity = torch.sum(lin_vel_w * dist_vec, dim=-1)
    return torch.clamp(approach_velocity, -10.0, 10.0)

# [æ¶æ„å¸ˆæ–°å¢] å¯¹å‡†å¥–åŠ±ï¼šåªè¦è½¦å¤´å¯¹å¾—å‡†ï¼Œå°±ç»™åˆ†ã€‚é¼“åŠ±åŸåœ°è½¬å‘ã€‚
def reward_facing_target(env: ManagerBasedRLEnv, command_name: str, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    target_pos_w = env.command_manager.get_command(command_name)[:, :3]
    robot = env.scene[asset_cfg.name]
    robot_pos = torch.nan_to_num(robot.data.root_pos_w, nan=0.0, posinf=0.0, neginf=0.0)
    delta_pos = target_pos_w[:, :2] - robot_pos[:, :2]
    target_angle = torch.atan2(delta_pos[:, 1], delta_pos[:, 0])
    _, _, robot_yaw = euler_xyz_from_quat(robot.data.root_quat_w)
    robot_yaw = torch.nan_to_num(robot_yaw, nan=0.0, posinf=0.0, neginf=0.0)
    angle_error = wrap_to_pi(target_angle - robot_yaw)
    
    # èŒƒå›´ [0, 0.5]
    return REWARD_CONFIG["facing_reward_scale"] * torch.exp(
        -torch.abs(angle_error) / REWARD_CONFIG["facing_angle_scale"]
    )

# [æ¶æ„å¸ˆæ–°å¢] ç”Ÿå­˜æƒ©ç½šï¼šé€¼è¿«æœºå™¨äººåŠ¨èµ·æ¥
def reward_alive(env: ManagerBasedRLEnv) -> torch.Tensor:
    # è¿”å› -1.0 * æƒé‡
    return -REWARD_CONFIG["alive_penalty"] * torch.ones(env.num_envs, device=env.device)

# [æ¶æ„å¸ˆæ–°å¢] åŠ¨ä½œå¹³æ»‘åº¦å¥–åŠ±
def reward_action_smoothness(env: ManagerBasedRLEnv) -> torch.Tensor:
    diff = env.action_manager.action - env.action_manager.prev_action
    return -torch.sum(torch.square(diff), dim=1)

# [åˆ é™¤] å†²çªçš„å¥–åŠ±å‡½æ•°å®šä¹‰ï¼ˆç¬¬äºŒä¸ªç‰ˆæœ¬ï¼Œå¯¼è‡´æœºå™¨äººå€’è½¦åˆ·åˆ†ï¼‰
# åŸå› ï¼šPythonä½¿ç”¨æœ€åä¸€ä¸ªå®šä¹‰ï¼Œè€Œè¿™ä¸ªç‰ˆæœ¬å¥–åŠ±ä»»æ„æ–¹å‘çš„0.25m/sé€Ÿåº¦
# åæœï¼šæœºå™¨äººå­¦ä¼šå€’è½¦æ¥åˆ·åˆ†ï¼Œå¯¼è‡´"é†‰æ±‰èµ°è·¯"
#
# æ­£ç¡®ç‰ˆæœ¬åœ¨line 409ï¼Œåªå¥–åŠ±å‰è¿›é€Ÿåº¦

# æ—¥å¿—è®°å½•å‡½æ•°
def log_distance_to_goal(env: ManagerBasedRLEnv, command_name: str, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    target_pos = env.command_manager.get_command(command_name)[:, :2]
    robot_pos = torch.nan_to_num(env.scene[asset_cfg.name].data.root_pos_w[:, :2], nan=0.0, posinf=0.0, neginf=0.0)
    dist = torch.norm(target_pos - robot_pos, dim=-1)
    return dist

def log_linear_velocity(env: ManagerBasedRLEnv, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    robot = env.scene[asset_cfg.name]
    lin_vel_b = torch.nan_to_num(robot.data.root_lin_vel_b[:, :2], nan=0.0, posinf=0.0, neginf=0.0)
    return torch.norm(lin_vel_b, dim=-1)

# ç¨€ç–åˆ°è¾¾å¥–åŠ±
def reward_near_goal(env: ManagerBasedRLEnv, command_name: str, threshold: float, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    # [æ¶æ„å¸ˆä¿®å¤ 2026-01-24] ä¿®å¤åæ ‡ç³»ä¸ä¸€è‡´é—®é¢˜
    # é—®é¢˜ï¼šcommand_manager.get_command() è¿”å›çš„å¯èƒ½æ˜¯ç›¸å¯¹åæ ‡
    # è§£å†³ï¼šç›´æ¥è®¿é—®å‘½ä»¤å¯¹è±¡çš„ pose_command_w å±æ€§ï¼ˆä¸–ç•Œåæ ‡ç³»ï¼‰
    # ä½¿ç”¨ _terms è€Œä¸æ˜¯ _term_regsï¼ˆIsaac Lab 4.5ä¸­ç§»é™¤äº†_term_regsï¼‰
    command_term = env.command_manager._terms[command_name]
    target_pos_w = command_term.pose_command_w[:, :2]

    robot_pos = torch.nan_to_num(env.scene[asset_cfg.name].data.root_pos_w[:, :2], nan=0.0, posinf=0.0, neginf=0.0)
    dist = torch.norm(target_pos_w - robot_pos, dim=-1)
    return (dist < threshold).float()

def penalty_collision_force(env: ManagerBasedRLEnv, sensor_cfg: SceneEntityCfg, threshold: float) -> torch.Tensor:
    sensor: ContactSensor = env.scene[sensor_cfg.name]
    net_forces = torch.norm(sensor.data.net_forces_w, dim=-1)
    if net_forces.dim() > 1: net_forces = torch.max(net_forces, dim=-1)[0]
    net_forces = torch.nan_to_num(net_forces, nan=0.0, posinf=0.0, neginf=0.0)
    is_startup = env.episode_length_buf < 50
    penalty = (net_forces > threshold).float()
    penalty[is_startup] = 0.0
    return penalty

def penalty_out_of_bounds(env: ManagerBasedRLEnv, threshold: float, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    robot = env.scene[asset_cfg.name]
    robot_pos = torch.nan_to_num(robot.data.root_pos_w, nan=0.0, posinf=0.0, neginf=0.0)
    dist = torch.norm(robot_pos - env.scene.env_origins, dim=-1)
    return (dist > threshold).float()

# =============================================================================
# 4. ç»ˆæ­¢æ¡ä»¶
# =============================================================================

def check_out_of_bounds(env: ManagerBasedRLEnv, threshold: float, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    robot = env.scene[asset_cfg.name]
    robot_pos = torch.nan_to_num(robot.data.root_pos_w, nan=0.0, posinf=0.0, neginf=0.0)
    dist = torch.norm(robot_pos - env.scene.env_origins, dim=-1)
    return (dist > threshold)

def check_collision_simple(env: ManagerBasedRLEnv, sensor_cfg_base: SceneEntityCfg, threshold: float) -> torch.Tensor:
    sensor: ContactSensor = env.scene[sensor_cfg_base.name]
    forces = torch.norm(sensor.data.net_forces_w, dim=-1)
    if forces.dim() > 1: forces = torch.max(forces, dim=-1)[0]
    is_safe = env.episode_length_buf < 50 
    forces = torch.nan_to_num(forces, nan=0.0, posinf=0.0, neginf=0.0)
    return (forces > threshold) & (~is_safe)

def check_reach_goal(env: ManagerBasedRLEnv, command_name: str, threshold: float, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    # [æ¶æ„å¸ˆä¿®å¤ 2026-01-24] ä¿®å¤åæ ‡ç³»ä¸ä¸€è‡´é—®é¢˜
    # é—®é¢˜ï¼šcommand_manager.get_command() è¿”å›çš„å¯èƒ½æ˜¯ç›¸å¯¹åæ ‡
    # è§£å†³ï¼šç›´æ¥è®¿é—®å‘½ä»¤å¯¹è±¡çš„ pose_command_w å±æ€§ï¼ˆä¸–ç•Œåæ ‡ç³»ï¼‰
    # ä½¿ç”¨ _terms è€Œä¸æ˜¯ _term_regsï¼ˆIsaac Lab 4.5ä¸­ç§»é™¤äº†_term_regsï¼‰
    command_term = env.command_manager._terms[command_name]
    target_pos_w = command_term.pose_command_w[:, :2]

    robot_pos = torch.nan_to_num(env.scene[asset_cfg.name].data.root_pos_w[:, :2], nan=0.0, posinf=0.0, neginf=0.0)
    dist = torch.norm(target_pos_w - robot_pos, dim=-1)
    return (dist < threshold)

def check_time_out(env: ManagerBasedRLEnv) -> torch.Tensor:
    return (env.episode_length_buf >= env.max_episode_length)

def check_velocity_explosion(env: ManagerBasedRLEnv, threshold: float, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    robot = env.scene[asset_cfg.name]
    lin_vel = torch.norm(robot.data.root_lin_vel_w, dim=-1)
    ang_vel = torch.norm(robot.data.root_ang_vel_w, dim=-1)
    is_bad = torch.isnan(lin_vel) | torch.isnan(ang_vel) | torch.isinf(lin_vel) | torch.isinf(ang_vel)
    return (lin_vel > threshold) | (ang_vel > threshold) | is_bad

def check_base_height_bad(env: ManagerBasedRLEnv, min_height: float, max_height: float, asset_cfg: SceneEntityCfg) -> torch.Tensor:
    robot = env.scene[asset_cfg.name]
    z_pos = robot.data.root_pos_w[:, 2]
    is_bad = torch.isnan(z_pos) | torch.isinf(z_pos)
    return (z_pos < min_height) | (z_pos > max_height) | is_bad

def reset_root_state_safe_donut(env: ManagerBasedRLEnv, env_ids: torch.Tensor, min_radius: float, max_radius: float, asset_cfg: SceneEntityCfg):
    asset = env.scene[asset_cfg.name]
    min_r2 = min_radius ** 2
    max_r2 = max_radius ** 2
    r_sq = torch.rand(len(env_ids), device=env.device) * (max_r2 - min_r2) + min_r2
    r = torch.sqrt(r_sq)
    theta = torch.rand(len(env_ids), device=env.device) * 2 * math.pi - math.pi
    
    pos_x_local = r * torch.cos(theta)
    pos_y_local = r * torch.sin(theta)
    
    root_state = asset.data.default_root_state[env_ids].clone()
    root_state[:, 0] = pos_x_local + env.scene.env_origins[env_ids, 0]
    root_state[:, 1] = pos_y_local + env.scene.env_origins[env_ids, 1]
    root_state[:, 2] = 0.20 
    
    random_yaw = torch.rand(len(env_ids), device=env.device) * 2 * math.pi - math.pi
    zeros = torch.zeros_like(random_yaw)
    quat = quat_from_euler_xyz(zeros, zeros, random_yaw)
    root_state[:, 3:7] = quat
    
    asset.write_root_state_to_sim(root_state, env_ids=env_ids)

class RelativeRandomTargetCommand(mdp.UniformPoseCommand):
    def __init__(self, cfg, env):
        super().__init__(cfg, env)
        # [æ¶æ„å¸ˆä¿®æ­£ 2026-01-24] è¯¾ç¨‹å­¦ä¹ ï¼šä»è¿‘åˆ°è¿œ
        # ä¿®æ”¹å†å²ï¼š1.0-2.0 â†’ 0.5-1.5 â†’ 0.1-0.5ï¼ˆé€åˆ†é¢˜æµ‹è¯•ï¼‰â†’ 0.5-1.5ï¼ˆæ¢å¤æ­£å¸¸ï¼‰
        # éªŒè¯ï¼šé€åˆ†é¢˜æµ‹è¯•ç¡®è®¤ reach_goal ç³»ç»Ÿæ­£å¸¸ï¼ˆå·²è¾¾åˆ°100%ï¼‰
        # ç°çŠ¶ï¼šåæ ‡ç³»ä¸ä¸€è‡´é—®é¢˜å·²ä¿®å¤ï¼Œå¯ä»¥æ¢å¤æ­£å¸¸è®­ç»ƒ
        self.min_dist = 0.5  # âœ… æ¢å¤åˆ°è¯¾ç¨‹å­¦ä¹ èµ·å§‹è·ç¦»
        self.max_dist = 1.5  # âœ… æ¢å¤åˆ°è¯¾ç¨‹å­¦ä¹ ç›®æ ‡è·ç¦» 
        self.pose_command_w = torch.zeros(self.num_envs, 7, device=self.device)
        self.pose_command_w[:, 3] = 1.0 
        self.heading_command_w = torch.zeros(self.num_envs, device=self.device)
    
    def _resample_command(self, env_ids: torch.Tensor):
        robot = self._env.scene[self.cfg.asset_name]
        if robot is not None and robot.data.root_pos_w is not None:
            robot_pos = robot.data.root_pos_w[env_ids, :3]
            robot_pos = torch.nan_to_num(robot_pos, nan=0.0, posinf=0.0, neginf=0.0)
        else:
            robot_pos = torch.zeros((len(env_ids), 3), device=self.device)
        r = torch.empty(len(env_ids), device=self.device).uniform_(self.min_dist, self.max_dist)
        theta = torch.empty(len(env_ids), device=self.device).uniform_(-math.pi, math.pi)
        self.pose_command_w[env_ids, 0] = robot_pos[:, 0] + r * torch.cos(theta)
        self.pose_command_w[env_ids, 1] = robot_pos[:, 1] + r * torch.sin(theta)
        self.pose_command_w[env_ids, 2] = 0.0 
        self.pose_command_w[env_ids, 3] = 1.0 
        self.pose_command_w[env_ids, 4:] = 0.0
        self.heading_command_w[env_ids] = 0.0

    def _update_metrics(self):
        robot = self._env.scene[self.cfg.asset_name]
        root_pos_w = torch.nan_to_num(robot.data.root_pos_w, nan=0.0, posinf=0.0, neginf=0.0)
        
        target_pos_w = self.pose_command_w[:, :3]
        pos_error = torch.norm(target_pos_w[:, :2] - root_pos_w[:, :2], dim=-1)
        _, _, robot_yaw = euler_xyz_from_quat(robot.data.root_quat_w)
        robot_yaw = torch.nan_to_num(robot_yaw, nan=0.0, posinf=0.0, neginf=0.0)
        
        delta_pos = target_pos_w - root_pos_w
        target_yaw = torch.atan2(delta_pos[:, 1], delta_pos[:, 0])
        rot_error = wrap_to_pi(target_yaw - robot_yaw)
        self.metrics["position_error"] = pos_error
        self.metrics["orientation_error"] = torch.abs(rot_error)
        
    def _update_debug_vis(self, *args, **kwargs):
        pass

# =============================================================================
# é…ç½®ç±»
# =============================================================================

@configclass
class UniDiffDriveActionCfg(mdp.actions.JointVelocityActionCfg):
    class_type = UniDiffDriveAction
    asset_name: str = "robot"
    joint_names: list[str] = ["left_wheel_joint", "right_wheel_joint"]
    # [æ¶æ„å¸ˆä¿®æ­£ 2026-01-27] å¿…é¡»è®¾ä¸º 1.0ï¼
    # å› ä¸º UniDiffDriveAction å†…éƒ¨å·²ç»å®Œæˆäº†ä» [0,1] åˆ° [rad/s] çš„ç‰©ç†è½¬æ¢
    # å¦‚æœ scale != 1.0ï¼Œä¼šå¯¼è‡´åŒé‡ç¼©æ”¾ï¼Œé€Ÿåº¦å¤±æ§
    scale: float = 1.0
    use_default_offset: bool = False

@configclass
class RelativeRandomTargetCommandCfg(mdp.UniformPoseCommandCfg):
    class_type = RelativeRandomTargetCommand
    asset_name: str = "robot"
    body_name: str = "base_link"
    resampling_time_range: tuple[float, float] = (1.0e9, 1.0e9)
    # [æ¶æ„å¸ˆç´§æ€¥ä¿®å¤ 2026-01-27] é™ä½åˆå§‹éš¾åº¦ï¼šä»3mâ†’1.5m
    # é—®é¢˜ï¼šæœºå™¨äººè¿è·¯éƒ½ä¸ä¼šèµ°ï¼Œ3mèŒƒå›´å¤ªéš¾
    # è§£å†³ï¼šå…ˆåœ¨å¹¼å„¿å›­ï¼ˆ1.5mèŒƒå›´ï¼‰å­¦ä¼šåŸºæœ¬å¯¼èˆªï¼Œå†æ‰©å±•
    ranges: mdp.UniformPoseCommandCfg.Ranges = mdp.UniformPoseCommandCfg.Ranges(
        pos_x=(-1.5, 1.5), pos_y=(-1.5, 1.5), pos_z=(0.0, 0.0),  # âœ… 1.5m x 1.5mæ­£æ–¹å½¢åŒºåŸŸï¼ˆéš¾åº¦é™ä½75%ï¼‰
        roll=(0.0, 0.0), pitch=(0.0, 0.0), yaw=(-math.pi, math.pi)
    )
    debug_vis: bool = False

@configclass
class DashgoActionsCfg:
    wheels = UniDiffDriveActionCfg()

@configclass
class DashgoCommandsCfg:
    target_pose = RelativeRandomTargetCommandCfg()

@configclass
class DashgoObservationsCfg:
    @configclass
    class PolicyCfg(ObservationGroupCfg):
        history_length = 3

        # [æ¶æ„å¸ˆè­¦å‘Š 2026-01-27] âš ï¸ lidar å¿…é¡»ä¿æŒåœ¨ç¬¬ä¸€ä½ï¼
        # åŸå› ï¼šGeoNavPolicyä¾èµ–lidaråœ¨æœ€å‰é¢è¿›è¡Œæ•°æ®åˆ‡ç‰‡
        # é£é™©ï¼šå¦‚æœlidarç§»åˆ°å…¶ä»–ä½ç½®ï¼Œç½‘ç»œä¼šå°†é€Ÿåº¦æ•°æ®å½“æˆé›·è¾¾æ•°æ®
        # æ“ä½œï¼šæ·»åŠ /åˆ é™¤è§‚æµ‹é¡¹æ—¶ï¼Œç¡®ä¿lidarå§‹ç»ˆæ˜¯ç¬¬ä¸€ä¸ªå®šä¹‰çš„

        # [Geo-Distill V2.2] ä½¿ç”¨4å‘æ‹¼æ¥LiDAR (72ç»´)
        # ä¿®å¤åŸå› ï¼šå•ç›¸æœºæ— æ³•360Â° FOVï¼Œ4ä¸ª90Â°ç›¸æœºæ‹¼æ¥å®ç°å…¨å‘æ‰«æ
        lidar = ObservationTermCfg(
            func=process_stitched_lidar,
            params={}  # æ— éœ€sensor_cfgï¼Œå‡½æ•°å†…éƒ¨ç›´æ¥è®¿é—®4ä¸ªç›¸æœº
        )

        target_polar = ObservationTermCfg(func=obs_target_polar, params={"command_name": "target_pose", "asset_cfg": SceneEntityCfg("robot")})
        lin_vel = ObservationTermCfg(func=mdp.base_lin_vel, params={"asset_cfg": SceneEntityCfg("robot")})
        ang_vel = ObservationTermCfg(func=mdp.base_ang_vel, params={"asset_cfg": SceneEntityCfg("robot")})
        last_action = ObservationTermCfg(func=mdp.last_action)

        # [ä¼˜åŒ–] å¼€å¯è§‚æµ‹å™ªå£°ï¼Œå¢å¼ºSim2Realæ³›åŒ–èƒ½åŠ›ï¼ˆæ¶æ„å¸ˆå»ºè®®ï¼Œ2026-01-24ï¼‰
        def __post_init__(self):
            self.enable_corruption = True

    policy = PolicyCfg()


# ============================================================================
# è‡ªå®šä¹‰è¾…åŠ©å‡½æ•°
# ============================================================================

# [æ¶æ„å¸ˆæ–°å¢ 2026-01-24] è‡ªå®šä¹‰è¾…åŠ©å‡½æ•°ï¼šæ”¯æŒæ­£åˆ™åŒ¹é…çš„æ‰¹é‡éšœç¢ç‰©éšæœºåŒ–
# é—®é¢˜ï¼šSceneEntityCfg ä¸æ”¯æŒæ­£åˆ™è¡¨è¾¾å¼ï¼Œæ— æ³•ç›´æ¥åŒ¹é… "obs_.*"
# è§£å†³ï¼šç¼–å†™"ä¸­é—´å±‚"å‡½æ•°ï¼Œå…ˆæ­£åˆ™åŒ¹é…æ‰¾åˆ°æ‰€æœ‰éšœç¢ç‰©ï¼Œå†é€ä¸ªè°ƒç”¨å®˜æ–¹éšæœºåŒ–å‡½æ•°
def randomize_obstacles_by_pattern(env: ManagerBasedRLEnv, env_ids: torch.Tensor, pattern: str, pose_range: dict):
    """
    ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…éšœç¢ç‰©å¹¶æ‰¹é‡éšæœºåŒ–ä½ç½®

    Args:
        env: ç®¡ç†å‹RLç¯å¢ƒ
        env_ids: éœ€è¦é‡ç½®çš„ç¯å¢ƒID
        pattern: æ­£åˆ™è¡¨è¾¾å¼å­—ç¬¦ä¸²ï¼ˆå¦‚ "obs_.*" åŒ¹é…æ‰€æœ‰éšœç¢ç‰©ï¼‰
        pose_range: ä½ç½®å’Œæ—‹è½¬èŒƒå›´å­—å…¸
    """
    import re

    # 1. éå†åœºæ™¯ä¸­çš„æ‰€æœ‰èµ„äº§åç§°
    all_assets = list(env.scene.keys())

    # 2. ç­›é€‰å‡ºåŒ¹é…æ­£åˆ™æ¨¡å¼çš„èµ„äº§ (ä¾‹å¦‚ "obs_.*" åŒ¹é… "obs_inner_1", "obs_outer_2" ç­‰)
    matched_assets = [name for name in all_assets if re.match(pattern, name)]

    # 3. å¯¹æ¯ä¸ªåŒ¹é…åˆ°çš„éšœç¢ç‰©æ‰§è¡ŒéšæœºåŒ–
    for asset_name in matched_assets:
        # ä¸´æ—¶æ„é€  asset_cfgï¼ˆå€Ÿç”¨ SceneEntityCfg æ¥ä¼ é€’åå­—ï¼‰
        temp_cfg = SceneEntityCfg(asset_name)

        # è°ƒç”¨å®˜æ–¹çš„éšæœºåŒ–å‡½æ•°ï¼ˆåˆ©ç”¨ GPU å¹¶è¡Œå¤„ç† env_idsï¼‰
        mdp.reset_root_state_uniform(
            env,
            env_ids,
            pose_range=pose_range,
            velocity_range={},  # é™æ€éšœç¢ç‰©ä¸éœ€è¦é€Ÿåº¦
            asset_cfg=temp_cfg
        )


# ============================================================================
# é…ç½®ç±»å®šä¹‰
# ============================================================================

@configclass
class DashgoEventsCfg:
    reset_base = EventTermCfg(
        func=reset_root_state_safe_donut,
        mode="reset",
        params={
            "asset_cfg": SceneEntityCfg("robot"),
            "min_radius": 0.5,
            "max_radius": 0.8, 
        }
    )
    
    push_robot = EventTermCfg(
        func=mdp.push_by_setting_velocity,
        mode="interval",
        interval_range_s=(10.0, 15.0),
        params={
            "asset_cfg": SceneEntityCfg("robot"),
            "velocity_range": {
                "x": (-0.5, 0.5), 
                "y": (-0.5, 0.5), 
                "yaw": (-math.pi/6, math.pi/6)
            }
        }
    )
    
    randomize_mass = EventTermCfg(
        func=mdp.randomize_rigid_body_mass,
        mode="startup",
        params={
            "asset_cfg": SceneEntityCfg("robot"),
            "mass_distribution_params": (0.8, 1.2),
            "operation": "scale",
        }
    )
    
    physics_material = EventTermCfg(
        func=mdp.randomize_rigid_body_material,
        mode="startup",
        params={
            "asset_cfg": SceneEntityCfg("robot"),
            "static_friction_range": (0.7, 1.3),
            "dynamic_friction_range": (0.7, 1.3),
            "restitution_range": (0.0, 0.0),
            "num_buckets": 64,
        },
    )

    # [æ¶æ„å¸ˆæ–°å¢ 2026-01-24] éšœç¢ç‰©éšæœºåŒ– - èµ‹äºˆæ³›åŒ–èƒ½åŠ›
    # æ¯æ¬¡é‡ç½®æ—¶ï¼Œéšœç¢ç‰©çš„ä½ç½®åœ¨åŸä½ç½®åŸºç¡€ä¸Šéšæœºåç§» +/- 0.5ç±³ï¼Œéšæœºæ—‹è½¬
    # é€¼è¿«æœºå™¨äººå­¦ä¼šçœ‹è·¯ï¼Œè€Œä¸æ˜¯èƒŒåœ°å›¾ï¼Œå®ç°çœŸæ­£çš„æ³›åŒ–èƒ½åŠ›
    # [APIä¿®å¤ 2026-01-24] SceneEntityCfgä¸æ”¯æŒæ­£åˆ™ï¼Œä½¿ç”¨è‡ªå®šä¹‰å‡½æ•°
    randomize_obstacles = EventTermCfg(
        func=randomize_obstacles_by_pattern,  # âœ… è‡ªå®šä¹‰å‡½æ•°ï¼ˆæ”¯æŒæ­£åˆ™åŒ¹é…ï¼‰
        mode="reset",
        params={
            "pattern": "obs_.*",  # æ­£åˆ™è¡¨è¾¾å¼ï¼šåŒ¹é…æ‰€æœ‰åå­—å¸¦ obs_ çš„ç‰©ä½“
            "pose_range": {
                "x": (-0.5, 0.5),  # éšæœºåç§» +/- 0.5ç±³
                "y": (-0.5, 0.5),
                "yaw": (-math.pi, math.pi),  # éšæœºæ—‹è½¬ +/- 180åº¦
            },
        }
    )

@configclass
class DashgoSceneV2Cfg(InteractiveSceneCfg):
    # [æ¶æ„å¸ˆV3.7æœ€ç»ˆä¿®æ­£] å¿…é¡»ç”¨TerrainImporterCfgåŒ…è£…Generator
    terrain = TerrainImporterCfg(
        prim_path="/World/ground",
        terrain_type="generator",
        terrain_generator=TerrainGeneratorCfg(
            seed=42,
            size=(20.0, 20.0),
            border_width=2.5,
            num_rows=5,
            num_cols=5,
            sub_terrains={
                # [æ¶æ„å¸ˆV3.6æœ€ç»ˆç‰ˆ] åŸºäºæºç çš„çœŸå®å‚æ•°åˆ—è¡¨
                # [æ¶æ„å¸ˆV3.6æœ€ç»ˆç‰ˆ] åŸºäºæºç çš„çœŸå®å‚æ•°åˆ—è¡¨
                # 1. ç©ºæ—·åœ°å¸¦ (20%) - çº¯å¹³åœ°ï¼ˆnoise_rangeä¸º0ï¼‰
                "flat": HfRandomUniformTerrainCfg(
                    proportion=0.2,
                    horizontal_scale=0.1,
                    vertical_scale=0.005,
                    noise_range=(0.0, 0.0),
                    noise_step=0.01,  # [æ¶æ„å¸ˆV3.8] å¿…é¡»éé›¶ï¼é˜²æ­¢ ZeroDivisionError
                ),
                # 2. éšæœºéšœç¢æŸ± (40%) - å°èµ·ä¼
                "random_obstacles": HfRandomUniformTerrainCfg(
                    proportion=0.4,
                    horizontal_scale=0.1,
                    vertical_scale=0.005,
                    noise_range=(0.05, 0.2),
                    noise_step=0.01,
                ),
                # 3. è¿·å®«/èµ°å»Š (40%) - ç¦»æ•£éšœç¢ç‰©
                "maze": HfDiscreteObstaclesTerrainCfg(
                    proportion=0.4,
                    horizontal_scale=0.1,
                    vertical_scale=0.1,
                    border_width=1.0,
                    obstacle_height_range=(0.5, 1.0),
                    obstacle_width_range=(0.5, 2.0),
                    num_obstacles=40,
                ),
            },
            curriculum=True,
        ),
        max_init_terrain_level=5,
        collision_group=-1,
        physics_material=sim_utils.RigidBodyMaterialCfg(
            friction_combine_mode="average",
            restitution_combine_mode="average",
            static_friction=1.0,
            dynamic_friction=1.0,
        ),
    )

    robot = DASHGO_D1_CFG.replace(prim_path="{ENV_REGEX_NS}/Dashgo")
    
    contact_forces_base = ContactSensorCfg(
        prim_path="{ENV_REGEX_NS}/Dashgo/base_link", 
        history_length=3, track_air_time=True
    )

    # ============================================================================
    # [Geo-Distill V2.2] 4å‘æ·±åº¦ç›¸æœºæ‹¼æ¥æ–¹æ¡ˆ
    # ============================================================================
    #
    # é—®é¢˜ï¼šå•ç›¸æœºæ— æ³•å®ç°360Â° FOV (Pinhole>170Â°ä¼šä¸¥é‡ç•¸å˜)
    # è§£å†³ï¼šä½¿ç”¨4ä¸ª90Â°ç›¸æœºæ‹¼æ¥æˆ360Â°å…¨æ™¯æ·±åº¦å›¾
    #
    # æ‹¼æ¥é¡ºåºï¼ˆé€†æ—¶é’ˆï¼‰ï¼šFront(0Â°) â†’ Left(+90Â°) â†’ Back(180Â°) â†’ Right(-90Â°)
    # é™é‡‡æ ·ï¼š360 rays â†’ 72 points (æ¯5Â°ä¸€ä¸ªç‚¹)
    #
    # å®ç‰©å¯¹é½ï¼šEAI F4 LiDAR (360Â°æ‰«æã€5-12mèŒƒå›´ã€5-10Hzé¢‘ç‡)
    #
    # [æ¶æ„å¸ˆå»ºè®® 2026-01-27] âš ï¸ é‡è¦ï¼šå››å…ƒæ•°é¡ºåºéªŒè¯
    # - Isaac Sim ä½¿ç”¨ (w, x, y, z) é¡ºåº
    # - å¿…é¡»åœ¨ GUI ä¸­æ‰‹åŠ¨éªŒè¯ç›¸æœºæœå‘ï¼ˆé¿å…è£…åï¼‰
    # - éªŒè¯æ–¹æ³•ï¼šæ‰“å¼€ Isaac Sim GUI â†’ æ£€æŸ¥ 4 ä¸ªç›¸æœºçš„è§†é‡æ˜¯å¦æ­£ç¡®
    # ============================================================================

    # 1. å‰å‘ç›¸æœº (Front, 0Â°)
    #    Quaternion: (w, x, y, z) = (1.0, 0.0, 0.0, 0.0) â†’ Identity (0Â°æ—‹è½¬)
    camera_front = CameraCfg(
        prim_path="{ENV_REGEX_NS}/Dashgo/base_link/cam_front",
        update_period=0.1,  # 10 Hzï¼ˆæ¥è¿‘å®ç‰©5-10Hzï¼‰
        height=1, width=90,  # 90Â°åˆ†è¾¨ç‡
        data_types=["distance_to_image_plane"],
        spawn=sim_utils.PinholeCameraCfg(
            focal_length=24.0,
            focus_distance=400.0,
            horizontal_aperture=20.955,  # 90Â° FOV
            clipping_range=(0.1, 12.0),  # å¯¹é½EAI F4æœ€å¤§è·ç¦»
        ),
        offset=CameraCfg.OffsetCfg(
            pos=(0.0, 0.0, 0.13),  # å®‰è£…é«˜åº¦13cm
            rot=(1.0, 0.0, 0.0, 0.0),  # âœ… Identity quaternion (0Â°)
        ),
    )

    # 2. å·¦ä¾§ç›¸æœº (Left, +90Â°)
    #    Quaternion: (w, x, y, z) = (0.707, 0.0, 0.0, 0.707)
    #    å…¬å¼: (cos45Â°, 0, 0, sin45Â°) â†’ Zè½´+90Â°æ—‹è½¬
    camera_left = CameraCfg(
        prim_path="{ENV_REGEX_NS}/Dashgo/base_link/cam_left",
        update_period=0.1,
        height=1, width=90,
        data_types=["distance_to_image_plane"],
        spawn=sim_utils.PinholeCameraCfg(
            focal_length=24.0,
            focus_distance=400.0,
            horizontal_aperture=20.955,
            clipping_range=(0.1, 12.0),
        ),
        offset=CameraCfg.OffsetCfg(
            pos=(0.0, 0.0, 0.13),
            rot=(0.707, 0.0, 0.0, 0.707),  # âœ… Z+90Â° (sin45=0.707, cos45=0.707)
        ),
    )

    # 3. åå‘ç›¸æœº (Back, 180Â°)
    #    Quaternion: (w, x, y, z) = (0.0, 0.0, 1.0, 0.0)
    #    å…¬å¼: (cos90Â°, 0, 0, sin90Â°) â†’ Zè½´+180Â°æ—‹è½¬
    camera_back = CameraCfg(
        prim_path="{ENV_REGEX_NS}/Dashgo/base_link/cam_back",
        update_period=0.1,
        height=1, width=90,
        data_types=["distance_to_image_plane"],
        spawn=sim_utils.PinholeCameraCfg(
            focal_length=24.0,
            focus_distance=400.0,
            horizontal_aperture=20.955,
            clipping_range=(0.1, 12.0),
        ),
        offset=CameraCfg.OffsetCfg(
            pos=(0.0, 0.0, 0.13),
            rot=(0.0, 0.0, 1.0, 0.0),  # âœ… Z+180Â° (0,0,1,0)
        ),
    )

    # 4. å³ä¾§ç›¸æœº (Right, -90Â° / 270Â°)
    #    Quaternion: (w, x, y, z) = (-0.707, 0.0, 0.0, 0.707)
    #    å…¬å¼: (cos(-45Â°), 0, 0, sin(-45Â°)) â†’ Zè½´-90Â°æ—‹è½¬
    camera_right = CameraCfg(
        prim_path="{ENV_REGEX_NS}/Dashgo/base_link/cam_right",
        update_period=0.1,
        height=1, width=90,
        data_types=["distance_to_image_plane"],
        spawn=sim_utils.PinholeCameraCfg(
            focal_length=24.0,
            focus_distance=400.0,
            horizontal_aperture=20.955,
            clipping_range=(0.1, 12.0),
        ),
        offset=CameraCfg.OffsetCfg(
            pos=(0.0, 0.0, 0.13),
            rot=(-0.707, 0.0, 0.0, 0.707),  # âœ… Z-90Â° (sin-45=-0.707, cos-45=0.707)
        ),
    )
    
    obs_inner_1 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_In_1", spawn=sim_utils.CylinderCfg(radius=0.1, height=1.0, visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.8, 0.2, 0.2)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(1.6, 0.0, 0.5)))
    obs_inner_2 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_In_2", spawn=sim_utils.CuboidCfg(size=(0.2, 0.2, 1.0), visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.8, 0.4, 0.2)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(1.13, 1.13, 0.5)))
    obs_inner_3 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_In_3", spawn=sim_utils.CylinderCfg(radius=0.1, height=1.0, visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.8, 0.2, 0.2)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(0.0, 1.6, 0.5)))
    obs_inner_4 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_In_4", spawn=sim_utils.CuboidCfg(size=(0.2, 0.2, 1.0), visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.8, 0.4, 0.2)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(-1.13, 1.13, 0.5)))
    obs_inner_5 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_In_5", spawn=sim_utils.CylinderCfg(radius=0.1, height=1.0, visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.8, 0.2, 0.2)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(-1.6, 0.0, 0.5)))
    obs_inner_6 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_In_6", spawn=sim_utils.CuboidCfg(size=(0.2, 0.2, 1.0), visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.8, 0.4, 0.2)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(-1.13, -1.13, 0.5)))
    obs_inner_7 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_In_7", spawn=sim_utils.CylinderCfg(radius=0.1, height=1.0, visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.8, 0.2, 0.2)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(0.0, -1.6, 0.5)))
    obs_inner_8 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_In_8", spawn=sim_utils.CuboidCfg(size=(0.2, 0.2, 1.0), visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.8, 0.4, 0.2)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(1.13, -1.13, 0.5)))
    obs_outer_1 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_Out_1", spawn=sim_utils.CuboidCfg(size=(0.2, 0.2, 1.0), visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.2, 0.2, 0.8)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(2.3, 0.95, 0.5)))
    obs_outer_2 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_Out_2", spawn=sim_utils.CylinderCfg(radius=0.1, height=1.0, visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.2, 0.2, 0.8)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(0.95, 2.3, 0.5)))
    obs_outer_3 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_Out_3", spawn=sim_utils.CuboidCfg(size=(0.2, 0.2, 1.0), visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.2, 0.2, 0.8)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(-0.95, 2.3, 0.5)))
    obs_outer_4 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_Out_4", spawn=sim_utils.CylinderCfg(radius=0.1, height=1.0, visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.2, 0.2, 0.8)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(-2.3, 0.95, 0.5)))
    obs_outer_5 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_Out_5", spawn=sim_utils.CuboidCfg(size=(0.2, 0.2, 1.0), visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.2, 0.2, 0.8)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(-2.3, -0.95, 0.5)))
    obs_outer_6 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_Out_6", spawn=sim_utils.CuboidCfg(size=(0.2, 0.2, 1.0), visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.2, 0.2, 0.8)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(-0.95, -2.3, 0.5)))
    obs_outer_7 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_Out_7", spawn=sim_utils.CuboidCfg(size=(0.2, 0.2, 1.0), visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.2, 0.2, 0.8)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(0.95, -2.3, 0.5)))
    obs_outer_8 = RigidObjectCfg(prim_path="{ENV_REGEX_NS}/Obs_Out_8", spawn=sim_utils.CylinderCfg(radius=0.1, height=1.0, visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.2, 0.2, 0.8)), rigid_props=sim_utils.RigidBodyPropertiesCfg(kinematic_enabled=True), mass_props=sim_utils.MassPropertiesCfg(mass=20.0), collision_props=sim_utils.CollisionPropertiesCfg()), init_state=RigidObjectCfg.InitialStateCfg(pos=(2.3, -0.95, 0.5)))

@configclass
class DashgoRewardsCfg:
    """
    [v5.0 Ultimate] æ··åˆå¥–åŠ±æ¶æ„ï¼šSparseä¸»å¯¼ + Denseè¾…åŠ© + å¼ºçº¦æŸ

    è®¾è®¡ç†å¿µï¼š
        - reach_goal 2000.0ï¼šç»å¯¹ä¸»å¯¼ï¼Œç¡®ä¿"åˆ°è¾¾ç»ˆç‚¹"æ˜¯å…¨å±€æœ€ä¼˜è§£
        - shaping_distance 0.75+tanhï¼šé»„é‡‘å¹³è¡¡ï¼Œæä¾›æ–¹å‘æ„Ÿä½†é˜²æ­¢åˆ·åˆ†
        - Denseå¥–åŠ±ç»„ï¼šè§£å†³åˆæœŸè¿·èŒ«ï¼Œæé«˜å­¦ä¹ æ•ˆç‡
        - action_smoothness -0.01ï¼šæŠ‘åˆ¶é«˜é¢‘æŠ–åŠ¨ï¼Œæ²»æ„ˆNoise 17.0
        - collision -50.0+10.0é˜ˆå€¼ï¼šç—›æ„Ÿæ•™è‚²ï¼Œç¡®ç«‹å®‰å…¨è¾¹ç•Œ
    """

    # [ä¸»å¯¼] ç»ˆç‚¹å¤§å¥–ï¼š100åˆ†ï¼ˆV3.0é™ä½æƒé‡ï¼Œé˜²æ­¢reward hackingï¼‰
    # âœ… [V3.0] 2000.0 â†’ 100.0ï¼Œé¿å…è¿‡åº¦ä¸»å¯¼
    # âœ… [V5.1ä¿®å¤ 2026-01-30] threshold 0.25m â†’ 1.0mï¼Œä¿®å¤é˜ˆå€¼é”™ä½é—®é¢˜
    # åŸå› ï¼šç»ˆæ­¢é˜ˆå€¼=1.0mï¼Œå¥–åŠ±é˜ˆå€¼=0.25mï¼Œå¯¼è‡´æœºå™¨äººè§¦å‘ç»ˆæ­¢æ—¶è¿˜æ²¡æ‹¿åˆ°å¥–åŠ±
    # è§£å†³ï¼šç»Ÿä¸€ä¸º1.0mï¼Œç¡®ä¿å…ˆæ‹¿é’±åé‡ç½®
    reach_goal = RewardTermCfg(
        func=reward_near_goal,
        weight=100.0,  # âœ… V3.0: ä»2000.0é™ä½åˆ°100.0
        params={
            "command_name": "target_pose",
            "threshold": 1.0,  # âœ… V5.1ä¿®å¤: ä»0.25mæ”¹ä¸º1.0mï¼ˆä¸ç»ˆæ­¢é˜ˆå€¼ä¸€è‡´ï¼‰
            "asset_cfg": SceneEntityCfg("robot")
        }
    )

    # [æ¶æ„å¸ˆç´§æ€¥ä¿®å¤ 2026-01-27] ä¿®å¤"æŒ‡å—é’ˆ"ï¼šæ ‡å‡†è´Ÿè·ç¦»å¥–åŠ±
    # é—®é¢˜ï¼šshaping_distance=0.0000ï¼ˆtanhå‡½æ•°å¤±æ•ˆï¼‰ï¼Œæœºå™¨äººæ²¡æœ‰æ–¹å‘æ„Ÿ
    # è§£å†³ï¼šä½¿ç”¨æœ¬åœ°log_distance_to_goalå‡½æ•°ï¼ˆæ¬§å‡ é‡Œå¾—è·ç¦»ï¼Œè´Ÿå·=è·ç¦»è¶Šå°å¥–åŠ±è¶Šå¤§ï¼‰
    # æ•°å­¦åŸç†ï¼šreward = -distanceï¼Œè·ç¦»ä»5mâ†’1mï¼Œå¥–åŠ±ä»-5â†’-1ï¼ˆå•è°ƒé€’å¢ï¼‰
    # æ³¨æ„ï¼šä½¿ç”¨æœ¬åœ°å‡½æ•°è€Œémdp.rewards.position_command_errorï¼ˆAPIä¸å­˜åœ¨äºIsaac Sim 4.5ï¼‰
    shaping_distance = RewardTermCfg(
        func=log_distance_to_goal,  # âœ… ä½¿ç”¨æœ¬åœ°å·²å®šä¹‰å‡½æ•°ï¼ˆline 745ï¼‰
        weight=-1.0,  # âš ï¸ è´Ÿå·ï¼šè·ç¦»è¶Šå°ï¼Œ(è·ç¦»*-1)è¶Šå¤§
        params={
            "command_name": "target_pose",
            "asset_cfg": SceneEntityCfg("robot")
        }
    )

    # [è¾…åŠ©] Denseå¥–åŠ±ç»„ (ä¿ç•™v3ä¼˜åŠ¿)
    # ä½œç”¨ï¼šè§£å†³åˆæœŸè¿·èŒ«ï¼Œæé«˜å­¦ä¹ æ•ˆç‡
    target_speed = RewardTermCfg(
        func=reward_target_speed,
        weight=1.0,
        params={"asset_cfg": SceneEntityCfg("robot")}
    )
    facing_goal = RewardTermCfg(
        func=reward_facing_target,
        weight=0.1,
        params={"command_name": "target_pose", "asset_cfg": SceneEntityCfg("robot")}
    )

    # [å…¼å®¹] ä¿ç•™velodyne_style_rewardï¼ˆæ­£å¸¸æ¨¡å¼ä¸‹ï¼‰
    # [ä¿®å¤ 2026-01-27] æ³¨é‡Šæ‰ï¼šåœºæ™¯ä¸­æ²¡æœ‰ 'lidar_sensor' å®ä½“ï¼Œå¯¼è‡´ç¯å¢ƒåˆ›å»ºå¤±è´¥
    # ç°åœ¨æ”¹ç”¨åŸºäºç‰©ç†æ¥è§¦çš„é¿éšœï¼ˆundesired_contactsï¼‰+ åŠ¿èƒ½å¼•å¯¼ï¼ˆdistance_trackingï¼‰
    # if not is_headless_mode():
    #     velodyne_style_reward = RewardTermCfg(
    #         func=reward_navigation_sota,
    #         weight=1.0,
    #         params={
    #             "asset_cfg": SceneEntityCfg("robot"),
    #             "sensor_cfg": SceneEntityCfg("lidar_sensor"),  # â† å®ä½“ä¸å­˜åœ¨ï¼Œå·²å¼ƒç”¨
    #             "command_name": "target_pose"
    #         }
    #     )

    # [çº¦æŸ] åŠ¨ä½œå¹³æ»‘ï¼š0.01
    # ä½œç”¨ï¼šæŠ‘åˆ¶é«˜é¢‘æŠ–åŠ¨ï¼Œæ²»æ„ˆNoise 17.0
    action_smoothness = RewardTermCfg(
        func=reward_action_smoothness,
        weight=0.01,  # âœ… [v6.0ä¿®å¤] ä¿®å¤åŒé‡è´Ÿå·é”™è¯¯ï¼ˆè´Ÿå‡½æ•°Ã—è´Ÿæƒé‡=æ­£å¥–åŠ±åˆ·åˆ†æ¼æ´ï¼‰
    )

    # [çº¦æŸ] çŒ›çƒˆç¢°æ’æƒ©ç½šï¼š-500.0ï¼ˆç»å¯¹ç¦æ­¢ï¼‰
    # âœ… [V3.0] -200.0 â†’ -500.0ï¼Œæ­»åˆ‘çº§æƒ©ç½š
    # ä½œç”¨ï¼šæ’å‡»ç›´æ¥é‡ç½®å‰çš„è´Ÿåé¦ˆï¼ˆè™½ç„¶ Termination ä¼šå¤„ç†ï¼Œä½†é¢å¤–æ‰£åˆ†åŠ å¼ºè®°å¿†ï¼‰
    collision = RewardTermCfg(
        func=penalty_collision_force,
        weight=-500.0,  # âœ… V3.0: ä»-200.0æé«˜åˆ°-500.0
        params={
            "sensor_cfg": SceneEntityCfg("contact_forces_base"),
            "threshold": 10.0
        }
    )

    # [èåˆæ–¹æ¡ˆ: Architectæ¿€è¿›ç­–ç•¥] å¼ºåŒ–ç‰©ç†é¿éšœé˜²çº¿
    # é˜ˆå€¼1.0Nè¿‡æ»¤ç©ºæ°”æ‘©æ“¦å™ªå£°ï¼Œæƒé‡-2.0ä¸¥å‰æƒ©ç½šæ’å¢™
    # ä¿¡ä»»PhysXå¼•æ“çš„æ¥è§¦åŠ›æ£€æµ‹ï¼ˆæ¯”è§†è§‰æ›´å¯é ï¼‰
    undesired_contacts = RewardTermCfg(
        func=penalty_undesired_contacts,
        weight=-2.0,
        params={
            "sensor_cfg": SceneEntityCfg("contact_forces_base"),
            "threshold": 1.0  # æé«˜é˜ˆå€¼ï¼Œè¿‡æ»¤å™ªå£°ï¼ˆä»0.1Næ”¹ä¸º1.0Nï¼‰
        }
    )

    # [èåˆæ–¹æ¡ˆ: Assistantä¼˜åŒ–] æ‰©å¤§å®‰å…¨è·ç¦»ï¼Œæ›´ç¬¦åˆSim2Realéœ€æ±‚
    # 0.25må¯¹äºåŠå¾„0.2mçš„æœºå™¨äººæ¥è¯´å°±æ˜¯è´´è„¸ï¼Œ0.5mæ˜¯åˆç†çš„å®‰å…¨ä½™é‡
    unsafe_speed_penalty = RewardTermCfg(
        func=penalty_unsafe_speed,
        weight=-5.0,  # ä¸­ç­‰æ‰£åˆ†ï¼Œè¶…é€Ÿå¿…ç½š
        params={
            "asset_cfg": SceneEntityCfg("robot"),
            "min_dist_threshold": 0.5  # âœ… ä»0.25mæ”¹ä¸º0.5mï¼ˆæ›´åˆç†çš„å®‰å…¨ä½™é‡ï¼‰
        }
    )

    # [èåˆæ–¹æ¡ˆ: Architectæ¿€è¿›ç­–ç•¥ + Assistantæˆ˜æœ¯ä¼˜åŒ–]
    # æ¿€æ´»ç”Ÿå­˜å‹åŠ›ï¼š-0.1/æ­¥ï¼Œé€¼è¿«æœºå™¨äººåŠ¨èµ·æ¥
    # æ€»æ­¥æ•°500æ­¥â†’æ‰£50åˆ†ï¼Œç›¸æ¯”+2000çš„å¤§å¥–å¾®ä¸è¶³é“ï¼Œä½†è¶³ä»¥é˜»æ­¢åŸåœ°å‘å‘†
    alive_penalty = RewardTermCfg(func=reward_alive, weight=-0.1)

    # [èåˆæ–¹æ¡ˆ: Assistantä¼˜åŒ–] æ—¥å¿—é¡¹ä¸å‚ä¸è®­ç»ƒï¼Œä½†è®¾ä¸º1.0æ–¹ä¾¿TensorBoardè§‚å¯Ÿ
    log_distance = RewardTermCfg(
        func=log_distance_to_goal,
        weight=1.0,
        params={
            "command_name": "target_pose",
            "asset_cfg": SceneEntityCfg("robot")
        }
    )

    log_velocity = RewardTermCfg(
        func=log_linear_velocity,
        weight=0.0,
        params={"asset_cfg": SceneEntityCfg("robot")}
    )

    out_of_bounds = RewardTermCfg(
        func=penalty_out_of_bounds,
        weight=-200.0,
        params={"threshold": 8.0, "asset_cfg": SceneEntityCfg("robot")}
    )

@configclass
class DashgoTerminationsCfg:
    time_out = TerminationTermCfg(func=check_time_out, time_out=True)

    # [èåˆæ–¹æ¡ˆ: Architect+Assistantå…±è¯†] æ”¾å®½é€šå…³åˆ¤å®šï¼Œå…ˆè®©å®ƒå®¹æ˜“èµ¢å»ºç«‹ä¿¡å¿ƒ
    # é€»è¾‘ï¼šç”±å®½å…¥çª„ã€‚è®­ç»ƒåˆæœŸ0.5må¤ªä¸¥ï¼Œ1.0mæ›´ç¬¦åˆå±€éƒ¨å¯¼èˆªå®é™…éœ€æ±‚
    reach_goal = TerminationTermCfg(
        func=check_reach_goal,
        params={
            "command_name": "target_pose",
            "threshold": 1.0,  # âœ… ä»0.5mæ”¾å®½åˆ°1.0m
            "asset_cfg": SceneEntityCfg("robot")
        }
    )

    object_collision = TerminationTermCfg(
        func=check_collision_simple,
        params={"sensor_cfg_base": SceneEntityCfg("contact_forces_base"), "threshold": 50.0}  # âœ… [v8.0] é™ä½åˆ°50Nï¼Œæ›´æ•æ„Ÿ
    )
    out_of_bounds = TerminationTermCfg(func=check_out_of_bounds, params={"threshold": 8.0, "asset_cfg": SceneEntityCfg("robot")})
    base_height = TerminationTermCfg(func=check_base_height_bad, params={"min_height": -0.50, "max_height": 1.0, "asset_cfg": SceneEntityCfg("robot")})
    bad_velocity = TerminationTermCfg(func=check_velocity_explosion, params={"threshold": 50.0, "asset_cfg": SceneEntityCfg("robot")})

# =============================================================================
# [v5.0 Ultimate] è¯¾ç¨‹å­¦ä¹ é…ç½®
# =============================================================================

@configclass
class DashgoCurriculumCfg:
    """
    [v5.1 ACL] è‡ªé€‚åº”è¯¾ç¨‹å­¦ä¹ é…ç½®

    æ¶æ„å¸ˆå®¡è®¡å‘ç°ï¼šçº¿æ€§è¯¾ç¨‹å¯èƒ½å¯¼è‡´æœºå™¨äººé™·å…¥ç“¶é¢ˆ
    è§£å†³æ–¹æ¡ˆï¼šåŸºäºæˆåŠŸç‡åŠ¨æ€è°ƒæ•´éš¾åº¦ï¼Œä¿æŒåœ¨ZPD [40%, 80%]

    ä¸¤ç§æ¨¡å¼é€‰æ‹©ï¼š
        1. ACLæ¨¡å¼ï¼ˆæ¨èï¼‰ï¼šæ ¹æ®æˆåŠŸç‡è‡ªåŠ¨è°ƒæ•´
        2. çº¿æ€§æ¨¡å¼ï¼ˆä¼ ç»Ÿï¼‰ï¼šå›ºå®šæ­¥æ•°çº¿æ€§å¢åŠ 

    é€‰æ‹©æ–¹æ³•ï¼šæ³¨é‡Šæ‰ä¸éœ€è¦çš„æ¨¡å¼
    """
    # [v5.1 ACL] æ¨¡å¼1ï¼šè‡ªé€‚åº”è¯¾ç¨‹å­¦ä¹ ï¼ˆæ¨èï¼‰
    # ä¼˜åŠ¿ï¼šåŠ¨æ€è°ƒæ•´ï¼Œé¿å…ç“¶é¢ˆï¼Œå­¦ä¹ æ•ˆç‡+30-50%
    target_adaptive = CurriculumTermCfg(
        func=curriculum_adaptive_distance,
        params={
            "command_name": "target_pose",
            "initial_dist": 1.5,         # åˆå§‹éš¾åº¦ï¼š1.5ç±³ï¼ˆå¹¼å„¿å›­ï¼‰
            "max_dist": 8.0,              # æ¯•ä¸šéš¾åº¦ï¼š8ç±³ï¼ˆä¸“å®¶åŒºï¼‰
            "step_size": 0.5,             # æ¯æ¬¡è°ƒæ•´Â±0.5ç±³
            "upgrade_threshold": 0.8,     # SR > 80% å‡çº§
            "downgrade_threshold": 0.4,   # SR < 40% é™çº§
            "window_size": 100,           # è¯„ä¼°æœ€è¿‘100ä¸ªepisode
        }
    )

    # [v5.0 Legacy] æ¨¡å¼2ï¼šçº¿æ€§è¯¾ç¨‹å­¦ä¹ ï¼ˆä¼ ç»Ÿï¼Œå·²ç¦ç”¨ï¼‰
    # ä¼˜åŠ¿ï¼šå¯é¢„æµ‹ï¼Œç¨³å®š
    # åŠ£åŠ¿ï¼šå¯èƒ½å¯¼è‡´ç“¶é¢ˆï¼ˆæœºå™¨äººé•¿æœŸå¤±è´¥ï¼‰
    # target_expansion = CurriculumTermCfg(
    #     func=curriculum_expand_target_range,
    #     params={
    #         "command_name": "target_pose",
    #         "min_limit": 1.5,
    #         "max_limit": 8.0,
    #         "start_step": 0,
    #         "end_step": 300_000_000,
    #     }
    # )

@configclass
class DashgoNavEnvV2Cfg(ManagerBasedRLEnvCfg):
    decimation = 4
    episode_length_s = 90.0  # âœ… [æ¶æ„å¸ˆä¿®æ­£ 2026-01-24] è¯¾ç¨‹å­¦ä¹ ï¼šä» 60s å¢åŠ åˆ° 90sï¼ˆ1350æ­¥ï¼‰ï¼Œç»™æœºå™¨äººæ›´å¤šæ—¶é—´ç»•è¿‡éšœç¢ç‰©
    scene = DashgoSceneV2Cfg(num_envs=16, env_spacing=15.0)
    sim = sim_utils.SimulationCfg(dt=1/60, render_interval=10)

    actions = DashgoActionsCfg()
    observations = DashgoObservationsCfg()
    commands = DashgoCommandsCfg()
    events = DashgoEventsCfg()
    rewards = DashgoRewardsCfg()
    terminations = DashgoTerminationsCfg()
    curriculum = DashgoCurriculumCfg()  # âœ… [v5.0] å¯ç”¨è‡ªåŠ¨è¯¾ç¨‹å­¦ä¹ 