#!/usr/bin/env python3
"""
DashGo æ¨ç†è„šæœ¬ (play.py) v6.0
åŠŸèƒ½ï¼šåŠ è½½è®­ç»ƒå¥½çš„ GeoNavPolicy v3.1 æ¨¡å‹å¹¶å¯è§†åŒ–è¿è¡Œ

ä¿®å¤å†å²:
- v6.0: ä½¿ç”¨ GeoNavPolicy æ›¿ä»£ ActorCriticï¼Œè§£å†³æƒé‡ä¸åŒ¹é…é—®é¢˜
- ä¿®å¤: æ­£ç¡®å¤„ç† TensorDict è§‚æµ‹
- ä¿®å¤: æ·»åŠ ç‰©ç†é¢„çƒ­å¾ªç¯
"""

import argparse
import os
import torch

# Isaac Lab æ ¸å¿ƒ - å¿…é¡»æœ€å…ˆå¯¼å…¥
from isaaclab.app import AppLauncher

# ==============================================================================
# 1. å¯åŠ¨ä»¿çœŸå™¨
# ==============================================================================
parser = argparse.ArgumentParser(description="DashGo Play Policy")
parser.add_argument("--num_envs", type=int, default=1, help="Number of environments")
parser.add_argument("--checkpoint", type=str, default=None, help="Path to model checkpoint")
parser.add_argument("--num_episodes", type=int, default=None, help="Number of episodes to run")

# æ·»åŠ  AppLauncher å‚æ•°
AppLauncher.add_app_launcher_args(parser)
args_cli = parser.parse_args()

# å¼ºåˆ¶å¼€å¯ç›¸æœºï¼ˆç¯å¢ƒéœ€è¦ï¼‰
if not args_cli.enable_cameras:
    args_cli.enable_cameras = True

app_launcher = AppLauncher(args_cli)
simulation_app = app_launcher.app

print("\n" + "=" * 80)
print("ğŸ¤– [Isaac Sim] å¼•æ“å¯åŠ¨æˆåŠŸ... æ­£åœ¨åŠ è½½æ¨¡å—")
print("=" * 80)

# ==============================================================================
# 2. å»¶è¿Ÿå¯¼å…¥å…¶ä»–æ¨¡å—
# ==============================================================================
from isaaclab.envs import ManagerBasedRLEnv
from dashgo_env_v2 import DashgoNavEnvV2Cfg
from geo_nav_policy import GeoNavPolicy  # [å…³é”®] ä½¿ç”¨è®­ç»ƒæ—¶çš„ç­–ç•¥ç½‘ç»œ

def main():
    print("\n[INFO] åˆå§‹åŒ–æ¨ç†æµç¨‹...")

    # 1. åˆ›å»ºç¯å¢ƒ
    env_cfg = DashgoNavEnvV2Cfg()
    env_cfg.scene.num_envs = args_cli.num_envs
    print(f"[INFO] åˆ›å»ºç¯å¢ƒ (num_envs={env_cfg.scene.num_envs})...")

    try:
        env = ManagerBasedRLEnv(cfg=env_cfg)
        device = env.unwrapped.device
    except Exception as e:
        print(f"âŒ ç¯å¢ƒåˆ›å»ºå¤±è´¥: {e}")
        simulation_app.close()
        return

    # 2. é¢„çƒ­ç¯å¢ƒ & è·å–è§‚æµ‹æ ·æœ¬
    print("[INFO] ç¯å¢ƒé¢„çƒ­ & è·å–è§‚æµ‹æ ·æœ¬...")
    obs, _ = env.reset()

    # ç‰©ç†é¢„çƒ­ï¼ˆè®©æœºå™¨äººè½åˆ°åœ°é¢ï¼‰
    zero_actions = torch.zeros(env_cfg.scene.num_envs, 2, device=device)
    print("[INFO] ç‰©ç†é¢„çƒ­ä¸­ï¼ˆ10æ­¥ï¼‰...")
    for _ in range(10):
        env.step(zero_actions)
    obs, _ = env.reset()

    # 3. åˆå§‹åŒ– GeoNavPolicy ç½‘ç»œï¼ˆä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼‰
    num_actions = env.action_space.shape[1]
    print(f"[INFO] åŠ¨ä½œç»´åº¦: {num_actions}")
    print("[INFO] æ„å»º GeoNavPolicy v3.1 ç½‘ç»œ...")

    policy = GeoNavPolicy(
        obs=obs,
        obs_groups=None,
        num_actions=num_actions,
        actor_hidden_dims=[128, 64],
        critic_hidden_dims=[512, 256, 128],
        activation='elu',
        init_noise_std=1.0
    ).to(device)

    # 4. æŸ¥æ‰¾å¹¶åŠ è½½æ¨¡å‹æƒé‡
    if args_cli.checkpoint:
        model_path = args_cli.checkpoint
    else:
        # è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°æ¨¡å‹
        log_root = os.path.join(os.getcwd(), "logs")
        if not os.path.exists(log_root):
            print(f"âŒ æ—¥å¿—ç›®å½•ä¸å­˜åœ¨: {log_root}")
            simulation_app.close()
            return

        # æŸ¥æ‰¾æ‰€æœ‰ model_*.pt æ–‡ä»¶
        import glob
        import re
        model_files = glob.glob(os.path.join(log_root, "model_*.pt"))
        if not model_files:
            print(f"âŒ åœ¨ {log_root} æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
            simulation_app.close()
            return

        # æŒ‰è¿­ä»£æ¬¡æ•°æ’åºï¼Œå–æœ€æ–°çš„
        def extract_iter(f):
            m = re.search(r'model_(\d+).pt', f)
            return int(m.group(1)) if m else 0

        model_path = max(model_files, key=extract_iter)

    print(f"[INFO] åŠ è½½æƒé‡: {model_path}")

    try:
        loaded_dict = torch.load(model_path, map_location=device)

        # å¤„ç† state_dict é”®å
        if 'model_state_dict' in loaded_dict:
            state_dict = loaded_dict['model_state_dict']
        else:
            state_dict = loaded_dict

        # åŠ è½½æƒé‡ï¼ˆä¸¥æ ¼æ¨¡å¼ï¼‰
        policy.load_state_dict(state_dict, strict=True)
        print("âœ… æƒé‡åŠ è½½æˆåŠŸï¼")

    except Exception as e:
        print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        simulation_app.close()
        return

    # 5. åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
    policy.eval()

    # 6. æ¨ç†å¾ªç¯
    print("\n" + "=" * 80)
    print("ğŸš€ å¼€å§‹æ’­æ”¾ç­–ç•¥ (æŒ‰ Ctrl+C é€€å‡º)")
    print("=" * 80)

    ep_count = 0
    while simulation_app.is_running():
        with torch.no_grad():
            # ä½¿ç”¨ act_inference (ç¡®å®šæ€§ç­–ç•¥)
            actions = policy.act_inference(obs)

        # æ‰§è¡ŒåŠ¨ä½œ
        step_ret = env.step(actions)

        # å¤„ç†è¿”å›å€¼ï¼ˆå…¼å®¹4æˆ–5ä¸ªè¿”å›å€¼ï¼‰
        if len(step_ret) == 5:
            obs, _, term, trunc, _ = step_ret
            dones = term | trunc
        else:
            obs, _, dones, _ = step_ret

        # è®¡æ•°å®Œæˆçš„episode
        if torch.any(dones):
            ep_count += torch.sum(dones).item()
            if ep_count % 10 == 0:
                print(f"[Running] å®Œæˆ {int(ep_count)} ä¸ªepisode")

        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æŒ‡å®šepisodeæ•°
        if args_cli.num_episodes and ep_count >= args_cli.num_episodes:
            break

    print("\nâœ… æ¨ç†å®Œæˆ")
    simulation_app.close()

if __name__ == "__main__":
    main()
