Metrics/target\_pose/orientation\_error: 0.7801
      Episode\_Termination/time\_out: 1.0000
   Episode\_Termination/base\_height: 0.0000
    Episode\_Termination/reach\_goal: 0.0000
                   Total timesteps: 6912
                    Iteration time: 74.16s
                      Time elapsed: 00:10:39
                               ETA: 15:18:00
################################################################################
                       Learning iteration 9/2000
                       Computation: 10 steps/s (collection: 72.623s, learning 0.055s)
             Mean action noise std: 0.98
          Mean value\_function loss: 585.2465
               Mean surrogate loss: 0.0066
                 Mean entropy loss: 2.7880
                       Mean reward: -355.43
               Mean episode length: 147.61
   Episode\_Reward/progress\_to\_goal: 0.0042
         Episode\_Reward/reach\_goal: 0.0000
          Episode\_Reward/face\_goal: 0.1239
          Episode\_Reward/collision: -14.6007
        Episode\_Reward/action\_rate: -0.0193
        Episode\_Reward/stand\_still: -0.0968
Metrics/target\_pose/position\_error: 3.8033
Metrics/target\_pose/orientation\_error: 2.2725
      Episode\_Termination/time\_out: 1.0000
   Episode\_Termination/base\_height: 0.0000
    Episode\_Termination/reach\_goal: 0.0000
                   Total timesteps: 7680
                    Iteration time: 72.68s
                      Time elapsed: 00:11:51
                               ETA: 15:22:18
################################################################################
                       Learning iteration 10/2000
                       Computation: 10 steps/s (collection: 72.379s, learning 0.055s)
             Mean action noise std: 0.98
          Mean value\_function loss: 609.8743
               Mean surrogate loss: 0.0157
                 Mean entropy loss: 2.7879
                       Mean reward: -362.00
               Mean episode length: 150.31
   Episode\_Reward/progress\_to\_goal: 0.0460
         Episode\_Reward/reach\_goal: 0.0000
          Episode\_Reward/face\_goal: 0.3244
          Episode\_Reward/collision: -14.6684
        Episode\_Reward/action\_rate: -0.0272
        Episode\_Reward/stand\_still: -0.0966
Metrics/target\_pose/position\_error: 3.6168
Metrics/target\_pose/orientation\_error: 2.1684
      Episode\_Termination/time\_out: 1.0000
   Episode\_Termination/base\_height: 0.0000
    Episode\_Termination/reach\_goal: 0.0000
                   Total timesteps: 8448
                    Iteration time: 72.43s
                      Time elapsed: 00:13:04
                               ETA: 15:24:52
################################################################################
                       Learning iteration 11/2000
                       Computation: 10 steps/s (collection: 75.247s, learning 0.054s)
             Mean action noise std: 0.97
          Mean value\_function loss: 613.5337
               Mean surrogate loss: 0.0057
                 Mean entropy loss: 2.7809
                       Mean reward: -363.06
               Mean episode length: 150.92
   Episode\_Reward/progress\_to\_goal: 0.1082
         Episode\_Reward/reach\_goal: 0.0000
          Episode\_Reward/face\_goal: 0.4397
          Episode\_Reward/collision: -14.3733
        Episode\_Reward/action\_rate: -0.0170
        Episode\_Reward/stand\_still: -0.0922
Metrics/target\_pose/position\_error: 3.9745
Metrics/target\_pose/orientation\_error: 0.8489
      Episode\_Termination/time\_out: 1.0000
   Episode\_Termination/base\_height: 0.0000
    Episode\_Termination/reach\_goal: 0.0000
                   Total timesteps: 9216
                    Iteration time: 75.30s
                      Time elapsed: 00:14:19
                               ETA: 15:34:44
################################################################################
                       Learning iteration 12/2000
                       Computation: 10 steps/s (collection: 76.394s, learning 0.053s)
             Mean action noise std: 0.97
          Mean value\_function loss: 507.8948
               Mean surrogate loss: 0.0203
                 Mean entropy loss: 2.7770
                       Mean reward: -371.17
               Mean episode length: 155.00
   Episode\_Reward/progress\_to\_goal: -0.0269
         Episode\_Reward/reach\_goal: 0.0000
          Episode\_Reward/face\_goal: 0.2351
          Episode\_Reward/collision: -14.4549
        Episode\_Reward/action\_rate: -0.0199
        Episode\_Reward/stand\_still: -0.0944
Metrics/target\_pose/position\_error: 4.0741
Metrics/target\_pose/orientation\_error: 2.1061
      Episode\_Termination/time\_out: 1.0000
   Episode\_Termination/base\_height: 0.0000
    Episode\_Termination/reach\_goal: 0.0000
                   Total timesteps: 9984
                    Iteration time: 76.45s
                      Time elapsed: 00:15:36
                               ETA: 15:45:48
################################################################################
                       Learning iteration 13/2000
                       Computation: 10 steps/s (collection: 75.767s, learning 0.049s)
             Mean action noise std: 0.97
          Mean value\_function loss: 600.6950
               Mean surrogate loss: -0.0005
                 Mean entropy loss: 2.7769
                       Mean reward: -373.96
               Mean episode length: 156.25
   Episode\_Reward/progress\_to\_goal: 0.0278
         Episode\_Reward/reach\_goal: 0.0000
          Episode\_Reward/face\_goal: 0.3310
          Episode\_Reward/collision: -14.1233
        Episode\_Reward/action\_rate: -0.0186
        Episode\_Reward/stand\_still: -0.0874
Metrics/target\_pose/position\_error: 2.4392
Metrics/target\_pose/orientation\_error: 0.8375
      Episode\_Termination/time\_out: 1.0000
   Episode\_Termination/base\_height: 0.0000
    Episode\_Termination/reach\_goal: 0.0000
                   Total timesteps: 10752
                    Iteration time: 75.82s
                      Time elapsed: 00:16:51
                               ETA: 15:53:36
################################################################################
                       Learning iteration 14/2000
                       Computation: 9 steps/s (collection: 77.578s, learning 0.069s)
             Mean action noise std: 0.97
          Mean value\_function loss: 577.9873
               Mean surrogate loss: 0.0263
                 Mean entropy loss: 2.7812
                       Mean reward: -376.70
               Mean episode length: 157.73
   Episode\_Reward/progress\_to\_goal: -0.1595
         Episode\_Reward/reach\_goal: 0.0000
          Episode\_Reward/face\_goal: 0.3135
          Episode\_Reward/collision: -13.7101
        Episode\_Reward/action\_rate: -0.0226
        Episode\_Reward/stand\_still: -0.0801
Metrics/target\_pose/position\_error: 3.7772
Metrics/target\_pose/orientation\_error: 2.0931
      Episode\_Termination/time\_out: 1.0000
   Episode\_Termination/base\_height: 0.0000
    Episode\_Termination/reach\_goal: 0.0000
                   Total timesteps: 11520
                    Iteration time: 77.65s
                      Time elapsed: 00:18:09
                               ETA: 16:04:15
################################################################################
                       Learning iteration 15/2000
                       Computation: 10 steps/s (collection: 75.950s, learning 0.058s)
             Mean action noise std: 0.97
          Mean value\_function loss: 575.6421
               Mean surrogate loss: -0.0013
                 Mean entropy loss: 2.7807
                       Mean reward: -377.07
               Mean episode length: 158.08
   Episode\_Reward/progress\_to\_goal: -0.1374
         Episode\_Reward/reach\_goal: 0.0000
          Episode\_Reward/face\_goal: 0.2690
          Episode\_Reward/collision: -13.5243
        Episode\_Reward/action\_rate: -0.0259
        Episode\_Reward/stand\_still: -0.0768
Metrics/target\_pose/position\_error: 4.6389
Metrics/target\_pose/orientation\_error: 2.3228
      Episode\_Termination/time\_out: 1.0000
   Episode\_Termination/base\_height: 0.0000
    Episode\_Termination/reach\_goal: 0.0000
                   Total timesteps: 12288
                    Iteration time: 76.01s
                      Time elapsed: 00:19:25
                               ETA: 16:10:00
################################################################################
                       Learning iteration 16/2000
                       Computation: 9 steps/s (collection: 78.455s, learning 0.052s)
             Mean action noise std: 0.97
          Mean value\_function loss: 374.9504
               Mean surrogate loss: 0.0137
                 Mean entropy loss: 2.7765
                       Mean reward: -384.58
               Mean episode length: 161.00
   Episode\_Reward/progress\_to\_goal: -0.0457
         Episode\_Reward/reach\_goal: 0.0000
          Episode\_Reward/face\_goal: 0.2243
          Episode\_Reward/collision: -14.3698
        Episode\_Reward/action\_rate: -0.0321
        Episode\_Reward/stand\_still: -0.0885
Metrics/target\_pose/position\_error: 3.7687
Metrics/target\_pose/orientation\_error: 1.1864
      Episode\_Termination/time\_out: 1.0000
   Episode\_Termination/base\_height: 0.0000
    Episode\_Termination/reach\_goal: 0.0000
                   Total timesteps: 13056
                    Iteration time: 78.51s
                      Time elapsed: 00:20:44
                               ETA: 16:19:48
\^C(env\_isaaclab) gwh@GWH:\~/Dashgo\_RL\_Project\$ \~/IsaacLab/isaaclab.sh -p train\_v2.py --headless --num\_envs 16 --enable\_cameras
[INFO] Using python from: /home/gwh/.conda/envs/env\_isaaclab/bin/python
[INFO][AppLauncher]: Using device: cuda:0
[INFO][AppLauncher]: Loading experience file: /home/gwh/IsaacLab/apps/isaacsim\_4\_5/isaaclab.python.headless.rendering.kit
Loading user config located at: '/home/gwh/IsaacSim/kit/data/Kit/Isaac-Sim/4.5/user.config.json'
[Info] [carb] Logging to file: /home/gwh/IsaacSim/kit/logs/Kit/Isaac-Sim/4.5/kit\_20251120\_111859.log
2025-11-20 03:18:59 [0ms] [Warning] [omni.kit.app.plugin] No crash reporter present, dumps uploading isn't available.
2025-11-20 03:18:59 [2ms] [Warning] [omni.ext.plugin] [ext: rendering\_modes] Extensions config 'extension.toml' doesn't exist '/home/gwh/IsaacLab/apps/isaacsim\_4\_5/rendering\_modes' or '/home/gwh/IsaacLab/apps/isaacsim\_4\_5/rendering\_modes/config'
2025-11-20 03:18:59 [266ms] [Warning] [omni.datastore] OmniHub is inaccessible
|---------------------------------------------------------------------------------------------|
| Driver Version: 580.82.07     | Graphics API: Vulkan
|\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=|
| GPU | Name                             | Active | LDA | GPU Memory | Vendor-ID | LUID       |
|     |                                  |        |     |            | Device-ID | UUID       |
|     |                                  |        |     |            | Bus-ID    |            |
|---------------------------------------------------------------------------------------------|
| 0   | NVIDIA GeForce RTX 4060 Laptop.. | Yes: 0 |     | 8188    MB | 10de      | 0          |
|     |                                  |        |     |            | 28e0      | 5064f54e.. |
|     |                                  |        |     |            | 1         |            |
|\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=\=|
| OS: 20.04.6 LTS (Focal Fossa) ubuntu, Version: 20.04.6, Kernel: 5.15.0-139-generic
| XServer Vendor: The X.Org Foundation, XServer Version: 12013000 (1.20.13.0)
| Processor: AMD Ryzen 9 7945HX with Radeon Graphics
| Cores: 16 | Logical Cores: 32
|---------------------------------------------------------------------------------------------|
| Total Memory (MB): 31765 | Free Memory: 15671
| Total Page/Swap (MB): 9535 | Free Page/Swap: 9535
|--------------------------------------------------------------
