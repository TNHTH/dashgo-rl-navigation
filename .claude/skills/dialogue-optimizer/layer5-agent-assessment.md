# Layer 5: Agent评估与优化协议

> **按需加载**: 本文件是dialogue-optimizer skill的扩展协议，仅在评估Agent时加载
> **依赖**: 需要先加载SKILL.md (Layer 1-4)
> **版本**: V5.0 Full-Ecosystem

---

## 触发条件

**自动触发**（满足任一）：
1. 对话中使用了任何Agent（Code-Reviewer, Architect, Product等）
2. 用户说"评估agent"、"分析agent"、"优化agent"
3. 检测到Agent触发失败或输出质量问题
4. 用户明确要求"开始评估"

---

## Agent性能评估

### 1. 触发检测
```yaml
检查项:
  - Agent是否按预期自动触发？（检查Trigger配置）
  - Trigger关键词是否完整？（参考DR-018）
  - 是否存在DR-015违规？（创建Agent未添加Trigger）

示例：
  用户说："分析优化"
  预期：触发Code-Reviewer Agent
  实际：未触发（使用general-purpose）
  问题：CLAUDE.md缺少"分析优化"关键词
```

### 2. 输出质量评估
```yaml
评估维度:
  - 场景理解：是否Phase 0场景理解？（Code-Reviewer V3.0新增）
  - 务实性：是否过度设计？（AES加密200行 vs 环境变量1行）
  - 语言特性：是否理解语言特性？（Go: strings.Contains vs regexp）
  - 优先级：是否场景驱动？（抢课：成功率 > 安全）

评分标准:
  - 95分：场景驱动 + 务实主义 + 语言特性理解
  - 85分：基本正确但缺少场景适配
  - 75分：套用模板但有误（如正则优化建议错误）
  - <60分：严重错误或完全不适用场景
```

### 3. Token消耗与性价比评估

```yaml
评估维度:
  - 输入Token: 用户输入 + 上下文加载（代码文件、文档）
  - 输出Token: AI生成的评估报告
  - 总消耗: 输入 + 输出
  - 功能价值: 输出质量（0-100分）
  - 性价比: 功能价值 / Token消耗 × 100

Token估算方法:
  1. 输入Token: 读取文件大小（字节）/ 3 ≈ Token数
  2. 输出Token: 评估报告字符数 / 4 ≈ Token数
  3. 总消耗: 输入 + 输出

评分标准:
  - 🟢 高性价比: > 1.5（功能价值高，Token消耗低）
  - 🟡 中性价比: 0.5-1.5（平衡）
  - 🔴 低性价比: < 0.5（功能价值低或Token消耗高）

示例：
  Agent: Code-Reviewer
  输入: 8K tokens (代码文件)
  输出: 7K tokens (评估报告)
  总消耗: 15K tokens
  功能价值: 93.3分
  性价比: 93.3 / 15000 × 100 = 0.62
  评级: 🟡 中性价比

  优化建议:
  - 精简代码示例（引用替代重复）
  - 删除冗余说明
  - 目标: 15K → 10K (性价比0.62→0.93)
```

### 4. 错误模式识别
```yaml
常见错误模式:
  - 模板驱动：套用"最佳实践"而不理解场景
  - 过度设计：追求完美方案而非简单够用
  - 教条主义：忽视语言特性（Go正则、Python类型提示）
  - 优先级倒置：安全 > 成功率（抢课场景错误）

历史案例参考：
  - Code-Reviewer V2.0: 6大错误 → V3.0修正
  - 详见：.claude-temp/code-reviewer-learning_*/对话学习记录_*.md
```

---

## Agent优化建议

### 1. 版本迭代建议
```markdown
## Agent版本升级建议

### 当前版本: V2.0
### 目标版本: V3.0

### 主要改进:
1. **添加Phase 0: 场景理解**（必做）
   - 审查前先问：这是什么应用？核心目标？成败关键？

2. **修正错误模式**
   - ❌ 正则优化 → ✅ strings.Contains（Go语言）
   - ❌ AES加密 → ✅ 环境变量（务实主义）
   - ❌ Worker Pool → ✅ 直接goroutine（<10并发）

3. **添加语言特性检查**
   - Go: strings.Contains vs regexp, Context vs Sleep
   - Python: 类型提示, dataclass, with语句
   - C++: 智能指针, RAII, nullptr

4. **成本收益分析框架**
   - 优化建议 = 成本（行数）/ 收益（量化指标）
```

### 2. 自动更新Agent功能
```yaml
触发条件:
  - 评估评分 < 85分
  - 发现系统性错误（≥3个同类错误）
  - 用户确认更新

自动更新流程:
  1. 生成Agent更新计划（具体到行号修改）
  2. 列出修改清单：
     - 新增章节标题
     - 修正错误示例
     - 添加检查清单
  3. 等待用户确认（DR-016）
  4. 执行更新（Read → Edit → 确认）
  5. 创建学习记录文档（.claude-temp/）

示例：
  Agent: Code-Reviewer
  当前版本: V2.0 (75分)
  目标版本: V3.0 (95分)
  修改清单:
    - Line 33: 添加Phase 0场景理解
    - Line 167: 修正正则优化错误（添加警告）
    - Line 239: 添加并发与用户体验检查
    - Line 282: 添加务实主义设计章节
```

---

## Agent评估报告模板

```markdown
---
## 🤖 Agent评估报告

### Agent基本信息
- **名称**: Code-Reviewer
- **版本**: V2.0 → V3.0
- **文件**: multi-agent-system/agents/code-reviewer.prompt.md
- **评估时间**: 2026-01-23 14:32:15

### 性能评分
- **当前版本**: 75/100
- **目标版本**: 95/100
- **提升**: +20分

### Token消耗评估
- **输入Token**: 8K（代码文件）
- **输出Token**: 7K（评估报告）
- **总消耗**: 15K tokens
- **功能价值**: 93.3/100
- **性价比**: 0.62（🟡 中）
- **优化潜力**: 15K → 10K（精简33%）

### 主要问题

#### 🔴 严重错误（6个）
1. **正则优化建议错误**（性能倒退）
   - 错误：建议用regexp替代strings.Contains
   - 真相：Go的strings.Contains快1000倍
   - 修正：添加"常见错误优化"警告

2. **防DDoS逻辑颠倒**
   - 错误：客户端限速防DDoS
   - 真相：客户端限速防封号
   - 修正：改为"随机抖动模拟人类"

3. **AES加密过度设计**
   - 错误：200行AES加密
   - 真相：环境变量更安全（伪安全）
   - 修正：1行os.Getenv

4. **Worker Pool过度设计**
   - 错误：5个goroutine用Worker Pool
   - 真相：直接启动足够
   - 修正：删除Worker Pool建议

5. **优先级误判**
   - 错误：安全 > 重试机制
   - 真相：抢课场景成功率 > 安全
   - 修正：动态优先级模型

6. **Sleep阻塞问题**
   - 错误：time.Sleep(interval)
   - 真相：无法响应Ctrl+C
   - 修正：select监听ctx.Done()

### V3.0核心改进

#### 1. 添加Phase 0: 场景理解
```
审查前必问：
├─ 这是什么类型的应用？（CLI/Web/库/框架？）
├─ 核心目标是什么？（抢课成功/快速响应/安全防护？）
├─ 成功的关键因素？（网络稳定/性能优化/代码质量？）
└─ 失败的致命原因？（网络抖动/内存泄漏/安全漏洞？）
```

#### 2. 动态优先级模型
```
抢课脚本：成功率（重试）> 性能（连接池）> 安全（环境变量）
Web服务：安全 > 性能 > 可维护性
CLI工具：用户体验（Context退出）> 性能 > 安全
```

#### 3. 务实主义框架
```
优化建议前必问：
1. 实现成本是多少行代码？
2. 收益是什么？（量化：性能提升X%，成功率+Y%）
3. 是否有更低成本的替代方案？
4. 是否过度设计？（YAGNI原则）
```

### 成本收益对比

#### 高价值优化（推荐）
| 优化项 | 实现成本 | 预期收益 | 优先级 |
|--------|----------|----------|--------|
| 重试机制 | 30行 | 成功率+30% | 🔴 最高 |
| HTTP连接池 | 5行 | 延迟-60% | 🔴 最高 |
| 随机抖动 | 2行 | 封禁风险-80% | 🔴 最高 |

#### 低优先级（不推荐）
| 优化项 | 实现成本 | 预期收益 | 优先级 |
|--------|----------|----------|--------|
| AES加密 | 200行 | 安全性+0%（伪安全） | ❌ 不推荐 |
| Worker Pool | 50行 | 可维护性-10% | ❌ 过度设计 |

### 关键洞察

1. **场景优先 > 理论模板**
   - ❌ 套用"最佳实践"（正则预编译、AES加密）
   - ✅ 先理解场景，再定制方案

2. **务实主义 > 教条主义**
   - ❌ 追求"完美方案"（200行AES）
   - ✅ 简单够用 > 完美方案（1行环境变量）

3. **细节决定成败**
   - ❌ 忽略Sleep阻塞、Context监听
   - ✅ 用户体验、优雅退出、资源泄漏

### 学习记录
- 完整文档：`.claude-temp/code-reviewer-learning_2026-01-23/对话学习记录_01.md`
- 包含：6大错误详解、V3.0更新内容、成本收益分析

---
```

---

## 自动化规则建议

### 检测Agent触发失败
```yaml
场景: 用户说"分析优化"，但未触发Code-Reviewer
检测:
  - 用户关键词匹配Agent触发词
  - 实际调用的Agent类型
  - 是否使用了general-purpose

自动建议:
  - 触发词: "分析优化"、"代码分析"、"优化建议"
  - 建议: 添加到CLAUDE.md Trigger 1
  - 规则ID: DR-018
  - 全局适用性: ✅ 高（所有Agent触发检测）
```

---

## 评估后自动行动

```yaml
评估完成后的自动行动（需用户确认）:

1. **创建学习记录**
   - 路径: .claude-temp/{agent-name}-learning_{date}/对话学习记录_{序号}.md
   - 内容: 完整评估报告、错误分析、改进建议

2. **更新Agent版本**
   - 读取: multi-agent-system/agents/{agent-name}.prompt.md
   - 修改: 基于评估建议的具体行号
   - 确认: 等待用户确认（DR-016）
   - 执行: Edit工具应用修改

3. **更新系统配置**
   - 检查: 是否需要添加Trigger（DR-015检查）
   - 更新: CLAUDE.md添加触发条件
   - 记录: dynamic_rules.md添加新规则

4. **验证更新**
   - 测试: 重新运行Agent验证改进
   - 对比: 新版本输出 vs 旧版本输出
   - 记录: 更新学习文档

自动化示例（本次对话）:
  ✅ 评估完成
  ✅ 创建学习记录（.claude-temp/code-reviewer-learning_*/对话学习记录_01.md）
  ✅ 更新Agent（code-reviewer.prompt.md V2.0 → V3.0）
  ✅ 更新Trigger（CLAUDE.md添加DR-018）
  ✅ 更新规则（dynamic_rules.md添加DR-018）
```

---

## Prohibited Actions (Agent评估相关)

🚫 **NEVER**:
- 未经用户确认直接修改Agent文件（违反DR-016）
- 基于模板批评Agent而不理解场景
- 建议"伪安全"方案（AES加密本地文件）
- 忽略语言特性（Go vs Python vs C++差异）

✅ **ALWAYS**:
- Phase 0: 先理解场景再评估
- 务实主义: 简单够用 > 完美方案
- 成本收益: 量化优化价值（行数/收益比）
- 语言特性: 针对具体语言的优化建议

---

**版本**: V5.0 Full-Ecosystem
**最后更新**: 2026-01-23
