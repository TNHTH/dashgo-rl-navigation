# ğŸ” Reach Goal å¥–åŠ±è¯Šæ–­ç»“æœæŠ¥å‘Š

> **è¯Šæ–­æ—¶é—´**: 2026-01-30 02:00:00
> **è¯Šæ–­çŠ¶æ€**: âœ… å®Œæˆ
> **é—®é¢˜ç¡®è®¤**: ğŸ”´ é˜ˆå€¼é”™ä½å¯¼è‡´å¥–åŠ±æœªè§¦å‘

---

## ğŸ¯ æ ¸å¿ƒé—®é¢˜ç¡®è®¤

### é—®é¢˜ç—‡çŠ¶
```
Episode_Reward/reach_goal: 0.0000  # âŒ å§‹ç»ˆä¸º0
Episode_Termination/reach_goal: 0.78  # âœ… ç»ˆæ­¢æ­£å¸¸
Mean entropy loss: 6.17  # âŒ ç­–ç•¥æœªæ”¶æ•›
Mean value_function loss: 3519  # âŒ ä»·å€¼å‡½æ•°å´©æºƒ
```

### æ ¹æœ¬åŸå› ï¼š**é˜ˆå€¼é”™ä½** ğŸ”´

---

## ğŸ“Š è¯¦ç»†è¯Šæ–­ç»“æœ

### 1. Terminationsï¼ˆç»ˆæ­¢æ¡ä»¶ï¼‰

**ä½ç½®**: `dashgo_env_v2.py:1428-1435`

```python
reach_goal = TerminationTermCfg(
    func=check_reach_goal,
    params={
        "command_name": "target_pose",
        "threshold": 1.0,  # âœ… å®½æ¾é˜ˆå€¼ï¼ˆ1ç±³ï¼‰
        "asset_cfg": SceneEntityCfg("robot")
    }
)
```

**å…³é”®å‚æ•°**ï¼š
- é˜ˆå€¼ï¼š**1.0m**ï¼ˆ100cmï¼‰
- å‡½æ•°ï¼š`check_reach_goal`

**è§¦å‘æ¡ä»¶**ï¼šè·ç¦»ç›®æ ‡ < 1.0m æ—¶ï¼Œepisodeç»“æŸã€‚

---

### 2. Rewardsï¼ˆå¥–åŠ±å‡½æ•°ï¼‰

**ä½ç½®**: `dashgo_env_v2.py:1302-1310`

```python
reach_goal = RewardTermCfg(
    func=reward_near_goal,  # è‡ªå®šä¹‰å‡½æ•°
    weight=100.0,
    params={
        "command_name": "target_pose",
        "threshold": 0.25,  # âŒ ä¸¥æ ¼é˜ˆå€¼ï¼ˆ25cmï¼‰
        "asset_cfg": SceneEntityCfg("robot")
    }
)
```

**å…³é”®å‚æ•°**ï¼š
- é˜ˆå€¼ï¼š**0.25m**ï¼ˆ25cmï¼‰
- å‡½æ•°ï¼š`reward_near_goal`
- æƒé‡ï¼š100.0

**è§¦å‘æ¡ä»¶**ï¼šè·ç¦»ç›®æ ‡ < 0.25m æ—¶ï¼Œç»™100åˆ†ã€‚

---

### 3. reward_near_goal å‡½æ•°å®ç°

**ä½ç½®**: `dashgo_env_v2.py:790-800`

```python
def reward_near_goal(env, command_name, threshold, asset_cfg):
    # è®¡ç®—è·ç¦»
    command_term = env.command_manager._terms[command_name]
    target_pos_w = command_term.pose_command_w[:, :2]
    robot_pos = torch.nan_to_num(env.scene[asset_cfg.name].data.root_pos_w[:, :2])

    dist = torch.norm(target_pos_w - robot_pos, dim=-1)

    # è¿”å›ï¼šè·ç¦» < é˜ˆå€¼ â†’ 1.0ï¼Œå¦åˆ™ â†’ 0.0
    return (dist < threshold).float()
```

**å…³é”®å‘ç°**ï¼š
- è¿”å›ç±»å‹ï¼š**boolè½¬float**ï¼ˆ0.0æˆ–1.0ï¼‰
- ä¸æ˜¯è¿ç»­å¥–åŠ±ï¼Œæ˜¯ç¨€ç–çš„äºŒå…ƒå¥–åŠ±

---

## âŒ é—®é¢˜ç¡®è®¤ï¼šé˜ˆå€¼é”™ä½

### å¯¹æ¯”è¡¨

| ç»„ä»¶ | é˜ˆå€¼ | è§¦å‘éš¾åº¦ | å®é™…æ•ˆæœ |
|------|------|---------|----------|
| **Terminations** | 1.0m | å®¹æ˜“ï¼ˆå®½æ¾ï¼‰ | æœºå™¨äººåˆ°è¾¾1mâ†’episodeç»“æŸ |
| **Rewards** | 0.25m | å›°éš¾ï¼ˆä¸¥æ ¼ï¼‰| éœ€è¦åˆ°è¾¾0.25mâ†’æ‰ç»™100åˆ† |

### æ—¶åºåˆ†æ

```
æœºå™¨äººè¿åŠ¨è½¨è¿¹ï¼š
èµ·ç‚¹ â†’ 1.5m â†’ 1.0m â†’ 0.5m â†’ 0.3m â†’ 0.2m
       â†“      â†“      â†“      â†“      â†“
       ç»§ç»­   ç»§ç»­   [è§¦å‘ç»ˆæ­¢]  X      X
                    episodeç»“æŸ
                    reward=0.0
```

**å…³é”®æ—¶åˆ»**ï¼š
- è·ç¦» = 1.0m â†’ **è§¦å‘ç»ˆæ­¢**ï¼Œepisodeç»“æŸ
- æ­¤æ—¶è·ç¦»è¿˜è¿œå¤§äº0.25m â†’ **æ²¡è§¦å‘å¥–åŠ±**
- ç»“æœï¼š`Episode_Reward/reach_goal = 0.0000`

---

## ğŸ”¬ ä¸ºä»€ä¹ˆè®­ç»ƒè¿˜èƒ½è¿›è¡Œï¼Ÿ

### ç»ˆæ­¢ç‡é«˜çš„åŸå› 

è™½ç„¶`reach_goal=0`ï¼Œä½†ç»ˆæ­¢ç‡æœ‰78%ï¼ŒåŸå› æ˜¯ï¼š

1. **Time-outç»ˆæ­¢**ï¼š30ç§’æ—¶é—´åˆ°
2. **Collisionç»ˆæ­¢**ï¼šæ’å¢™
3. **Out-of-bounds**ï¼šè¶Šç•Œ
4. **Base-height/Bad-velocity**ï¼šå…¶ä»–å¤±è´¥æ¡ä»¶

### ä¸ºä»€ä¹ˆä»·å€¼å‡½æ•°å´©æºƒï¼Ÿ

```
æ°¸è¿œæ‹¿ä¸åˆ°reach_goalå¥–åŠ±(0åˆ†)
    â†“
ä»·å€¼å‡½æ•°æ— æ³•ä¼°è®¡"åˆ°è¾¾"çš„ä»·å€¼
    â†“
Value Lossçˆ†ç‚¸ï¼ˆ3519ï¼‰
    â†“
ç­–ç•¥æ¢¯åº¦æ— æ–¹å‘ï¼Œä¿æŒé«˜ç†µï¼ˆ6.17ï¼‰
    â†“
æœºå™¨äººéšæœºä¹±è·‘
```

---

## ğŸ’¡ è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆAï¼šç»Ÿä¸€é˜ˆå€¼ï¼ˆæœ€ç®€å•ï¼‰â­â­â­â­â­

**æ ¸å¿ƒæ€æƒ³**ï¼šè®©å¥–åŠ±é˜ˆå€¼ >= ç»ˆæ­¢é˜ˆå€¼

**ä¿®æ”¹ `dashgo_env_v2.py:1302-1310`**ï¼š

```python
reach_goal = RewardTermCfg(
    func=reward_near_goal,
    weight=100.0,
    params={
        "command_name": "target_pose",
        "threshold": 1.0,  # âœ… ä»0.25mæ”¹ä¸º1.0mï¼ˆä¸ç»ˆæ­¢ä¸€è‡´ï¼‰
        "asset_cfg": SceneEntityCfg("robot")
    }
)
```

**æ•ˆæœ**ï¼š
- æœºå™¨äººåˆ°è¾¾1.0mæ—¶ï¼Œå…ˆæ‹¿åˆ°100åˆ†å¥–åŠ±
- ç„¶åè§¦å‘ç»ˆæ­¢ï¼Œepisodeç»“æŸ
- ç»“æœï¼š`Episode_Reward/reach_goal > 0`

**ä¼˜ç‚¹**ï¼š
- âœ… æœ€å°ä¿®æ”¹ï¼ˆåªæ”¹1ä¸ªæ•°å­—ï¼‰
- âœ… é£é™©æœ€ä½
- âœ… ç«‹å³è§æ•ˆ

---

### æ–¹æ¡ˆBï¼šåå‘ä¿®æ”¹ï¼ˆæ›´ä¸¥æ ¼ï¼‰â­â­â­

**æ ¸å¿ƒæ€æƒ³**ï¼šè®©ç»ˆæ­¢é˜ˆå€¼ <= å¥–åŠ±é˜ˆå€¼

**ä¿®æ”¹ `dashgo_env_v2.py:1428-1435`**ï¼š

```python
reach_goal = TerminationTermCfg(
    func=check_reach_goal,
    params={
        "command_name": "target_pose",
        "threshold": 0.2,  # âœ… ä»1.0mæ”¹ä¸º0.2mï¼ˆæ¯”å¥–åŠ±æ›´ä¸¥ï¼‰
        "asset_cfg": SceneEntityCfg("robot")
    }
)
```

**æ•ˆæœ**ï¼š
- æœºå™¨äººåˆ°è¾¾0.25mæ—¶ï¼Œå…ˆæ‹¿åˆ°100åˆ†
- ç»§ç»­é è¿‘åˆ°0.2mæ—¶ï¼Œè§¦å‘ç»ˆæ­¢
- ç»“æœï¼š`Episode_Reward/reach_goal > 0`

**ä¼˜ç‚¹**ï¼š
- âœ… ä¿æŒåœè½¦ç²¾åº¦ï¼ˆ0.2mæ¯”1.0mæ›´å‡†ç¡®ï¼‰

**ç¼ºç‚¹**ï¼š
- âš ï¸ è®­ç»ƒéš¾åº¦å¢åŠ ï¼ˆé˜ˆå€¼æ›´ä¸¥ï¼‰
- âš ï¸ å¯èƒ½é™ä½æˆåŠŸç‡

---

### æ–¹æ¡ˆCï¼šåŒé‡å¥–åŠ±ï¼ˆæœ€ç¨³å¥ï¼‰â­â­â­â­

**æ ¸å¿ƒæ€æƒ³**ï¼šä¿ç•™0.25mçš„ç²¾ç¡®å¥–åŠ±ï¼Œä½†æ·»åŠ 1.0mçš„"æ¥è¿‘å¥–åŠ±"

**ä¿®æ”¹ `dashgo_env_v2.py:1287-1320`**ï¼š

```python
# [åŸæœ‰] ç²¾ç¡®åˆ°è¾¾å¥–åŠ±ï¼ˆä¿æŒï¼‰
reach_goal = RewardTermCfg(
    func=reward_near_goal,
    weight=100.0,
    params={
        "command_name": "target_pose",
        "threshold": 0.25,  # ä¿æŒç²¾ç¡®
        "asset_cfg": SceneEntityCfg("robot")
    }
)

# [æ–°å¢] æ¥è¿‘å¥–åŠ±ï¼ˆæä¾›å¼•å¯¼ï¼‰
approaching_goal = RewardTermCfg(
    func=reward_near_goal,  # å¤ç”¨å‡½æ•°
    weight=10.0,  # è¾ƒå°æƒé‡ï¼Œä½œä¸ºå¼•å¯¼
    params={
        "command_name": "target_pose",
        "threshold": 1.0,  # å®½æ¾é˜ˆå€¼ï¼Œæ¯”ç»ˆæ­¢æ—©è§¦å‘
        "asset_cfg": SceneEntityCfg("robot")
    }
)
```

**æ•ˆæœ**ï¼š
- åˆ°è¾¾1.0m â†’ å…ˆæ‹¿10åˆ†ï¼ˆæ¥è¿‘å¥–åŠ±ï¼‰
- ç»§ç»­é è¿‘åˆ°0.25m â†’ å†æ‹¿100åˆ†ï¼ˆç²¾ç¡®å¥–åŠ±ï¼‰
- è§¦å‘ç»ˆæ­¢

**ä¼˜ç‚¹**ï¼š
- âœ… æä¾›æŒç»­å¼•å¯¼
- âœ… ä¿æŒåœè½¦ç²¾åº¦
- âœ… å¥–åŠ±æ›´ä¸°å¯Œ

---

## ğŸ“Š æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | ä¿®æ”¹é‡ | é£é™© | é¢„æœŸæ•ˆæœ | æ¨èåº¦ |
|------|--------|------|----------|--------|
| **A: ç»Ÿä¸€é˜ˆå€¼åˆ°1.0m** | 1è¡Œä»£ç  | æä½ | ç«‹å³è§æ•ˆ | â­â­â­â­â­ |
| **B: ç»ˆæ­¢æ”¹ä¸º0.2m** | 1è¡Œä»£ç  | ä¸­-é«˜ | æ›´ç²¾ç¡®ï¼Œä½†éš¾åº¦å¢åŠ  | â­â­â­ |
| **C: åŒé‡å¥–åŠ±** | æ–°å¢1é¡¹ | ä½ | æœ€ç¨³å¥ | â­â­â­â­ |

---

## âš ï¸ å…³é”®è­¦å‘Š

### ä¸è¦æ‰§è¡Œçš„ä¿®æ”¹

1. âŒ **ä¸è¦æ¨¡ä»¿æ¶æ„å¸ˆçš„"é»„é‡‘ä¸‰è§’"**
   - 5ä¸ªå¥–åŠ±é¡¹å¤ªå¤æ‚
   - æƒé‡100.0 vs 5.0å¤±è¡¡
   - parking_bonusæéš¾è§¦å‘

2. âŒ **ä¸è¦ç”¨KLè‡ªé€‚åº”**
   - å½“å‰Value Loss=3519ï¼ˆç³»ç»Ÿå´©æºƒï¼‰
   - KLè‡ªé€‚åº”å¯èƒ½è®©LRâ†’0ï¼Œè®­ç»ƒåœæ»
   - åº”è¯¥å…ˆç”¨å›ºå®šLR

3. âŒ **ä¸è¦é™ä½learning_rate**
   - å½“å‰é—®é¢˜ä¸æ˜¯å­¦ä¹ ç‡è¿‡é«˜
   - é™ä½LRä¼šè®©è®­ç»ƒæ›´æ…¢

---

## ğŸš€ æ¨èæ‰§è¡Œæ–¹æ¡ˆA

### ä¿®æ”¹1è¡Œä»£ç ï¼ˆ`dashgo_env_v2.py:1307`ï¼‰

**å½“å‰ä»£ç **ï¼š
```python
"threshold": 0.25,  # âŒ å¤ªä¸¥æ ¼
```

**ä¿®æ”¹ä¸º**ï¼š
```python
"threshold": 1.0,  # âœ… ä¸ç»ˆæ­¢ä¸€è‡´
```

### å®Œæ•´ä¸Šä¸‹æ–‡

```python
    # [ä¸»å¯¼] ç»ˆç‚¹å¤§å¥–ï¼š100åˆ†
    reach_goal = RewardTermCfg(
        func=reward_near_goal,
        weight=100.0,
        params={
            "command_name": "target_pose",
            "threshold": 1.0,  # âœ… ä¿®æ”¹è¿™é‡Œï¼šä»0.25æ”¹ä¸º1.0
            "asset_cfg": SceneEntityCfg("robot")
        }
    )
```

### é¢„æœŸæ•ˆæœ

ä¿®æ”¹åï¼Œè®­ç»ƒ200-500æ¬¡è¿­ä»£ï¼š
```
Episode_Reward/reach_goal: > 0  # âœ… ç»ˆäºæ‹¿åˆ°é’±äº†
Mean value_function loss: < 500  # âœ… ç¨³å®š
Mean entropy loss: < 3.0  # âœ… æ”¶æ•›
```

---

## ğŸ“ éªŒè¯æ­¥éª¤

### æ­¥éª¤1ï¼šä¿®æ”¹ä»£ç ï¼ˆ1åˆ†é’Ÿï¼‰

ä¿®æ”¹ `dashgo_env_v2.py` ç¬¬1307è¡Œ

### æ­¥éª¤2ï¼šæ¸…ç†æ—§æ—¥å¿—ï¼ˆ1åˆ†é’Ÿï¼‰

```bash
rm -rf logs/dashgo_v5_auto/*
```

### æ­¥éª¤3ï¼šé‡å¯è®­ç»ƒï¼ˆç­‰å¾…ä½ çš„ç¡®è®¤ï¼‰

```bash
~/IsaacLab/isaaclab.sh -p train_v2.py --headless --num_envs 64
```

### æ­¥éª¤4ï¼šç›‘æ§æŒ‡æ ‡ï¼ˆæŒç»­è§‚å¯Ÿï¼‰

è§‚å¯ŸTensorboardï¼š
- `Episode_Reward/reach_goal` æ˜¯å¦ > 0
- `Mean value_function loss` æ˜¯å¦ < 500
- `Mean entropy loss` æ˜¯å¦ < 3.0

---

## ğŸ¯ æ€»ç»“

### é—®é¢˜ç¡®è®¤

**æ ¹æœ¬åŸå› **ï¼šé˜ˆå€¼é”™ä½
- ç»ˆæ­¢é˜ˆå€¼ï¼š1.0mï¼ˆå®½æ¾ï¼‰
- å¥–åŠ±é˜ˆå€¼ï¼š0.25mï¼ˆä¸¥æ ¼ï¼‰
- ç»“æœï¼šæœºå™¨äººè§¦å‘ç»ˆæ­¢æ—¶ï¼Œè¿˜æ²¡æ‹¿åˆ°å¥–åŠ±

### ä¿®å¤æ–¹æ¡ˆ

**æ¨èæ–¹æ¡ˆA**ï¼šç»Ÿä¸€é˜ˆå€¼åˆ°1.0m
- ä¿®æ”¹é‡ï¼š1è¡Œä»£ç ï¼ˆ1ä¸ªæ•°å­—ï¼‰
- é£é™©ï¼šæä½
- æ•ˆæœï¼šç«‹ç«¿è§å½±

### ä¸æ¨è

- âŒ æ¶æ„å¸ˆçš„"é»„é‡‘ä¸‰è§’"ï¼ˆå¤ªå¤æ‚ï¼‰
- âŒ KLè‡ªé€‚åº”ï¼ˆä¸å½“å‰çŠ¶æ€å†²çªï¼‰
- âŒ é™ä½learning_rateï¼ˆä¸æ˜¯æ ¹æœ¬é—®é¢˜ï¼‰

---

**è¯Šæ–­çŠ¶æ€**: âœ… å®Œæˆ
**é—®é¢˜ç¡®è®¤**: ğŸ”´ é˜ˆå€¼é”™ä½
**ä¿®å¤æ–¹æ¡ˆ**: æ–¹æ¡ˆAï¼ˆç»Ÿä¸€é˜ˆå€¼åˆ°1.0mï¼‰
**ç­‰å¾…ç¡®è®¤**: æ˜¯å¦æ‰§è¡Œä¿®æ”¹ï¼Ÿ

---

**åˆ›å»ºè€…**: Claude Code AI Assistant
**æœ€åæ›´æ–°**: 2026-01-30 02:00:00
