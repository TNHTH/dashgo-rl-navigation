seed: 42
device: 'cuda:0'

num_steps_per_env: 480 

num_mini_batches: 4
# [微调] 提高熵系数，鼓励早期探索
entropy_coef: 0.01

max_iterations: 10000
empirical_normalization: False 
save_interval: 50

experiment_name: "dashgo_nav"

obs_groups:
  policy: ["policy"]
  value: ["policy"]
  critic: ["policy"]

policy:
  class_name: ActorCritic
  init_noise_std: 0.8
  actor_hidden_dims: [512, 256, 128]
  critic_hidden_dims: [512, 256, 128]
  activation: 'elu'

algorithm:
  class_name: PPO
  value_loss_coef: 1.0
  use_clipped_value_loss: True
  clip_param: 0.2
  num_learning_epochs: 5
  
  # [关键修复] 提升学习率至标准值 3e-4，加速收敛
  learning_rate: 3.0e-4
  
  max_grad_norm: 1.0
  gamma: 0.99
  lam: 0.95
  desired_kl: 0.01