seed: 42
device: 'cuda:0'

num_steps_per_env: 480 

num_mini_batches: 4
# [微调] 提高熵系数，鼓励早期探索
entropy_coef: 0.01

max_iterations: 10000
empirical_normalization: False 
save_interval: 50

experiment_name: "dashgo_nav"

obs_groups:
  policy: ["policy"]
  value: ["policy"]
  critic: ["policy"]

policy:
  class_name: ActorCritic
  init_noise_std: 0.8
  actor_hidden_dims: [512, 256, 128]
  critic_hidden_dims: [512, 256, 128]
  activation: 'elu'

algorithm:
  class_name: PPO
  value_loss_coef: 1.0
  use_clipped_value_loss: True
  clip_param: 0.2
  num_learning_epochs: 5

  # [优化] 使用保守的学习率提高稳定性
  learning_rate: 1.0e-4  # 从3e-4降到1e-4，避免训练不稳定

  max_grad_norm: 1.0
  gamma: 0.99
  lam: 0.95
  desired_kl: 0.01