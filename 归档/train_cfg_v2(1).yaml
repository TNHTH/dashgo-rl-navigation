seed: 42
device: 'cuda:0'

# 增加步数和迭代次数，适应更难的任务
num_steps_per_env: 48 
max_iterations: 2000 
empirical_normalization: True
save_interval: 50

# [关键] 新实验名称，日志会存在 logs/rsl_rl/dashgo_nav_v2/
experiment_name: "dashgo_nav_v2" 

obs_groups:
  policy: ["policy"]
  value: ["policy"]
  critic: ["policy"]

policy:
  class_name: ActorCritic 
  init_noise_std: 1.0
  actor_hidden_dims: [256, 256, 256] # 加深网络，处理复杂环境
  critic_hidden_dims: [256, 256, 256]
  activation: 'elu'

algorithm:
  class_name: PPO 
  value_loss_coef: 1.0
  use_clipped_value_loss: True
  clip_param: 0.2
  entropy_coef: 0.01
  num_learning_epochs: 5
  num_mini_batches: 4
  learning_rate: 1.0e-3
  schedule: 'adaptive'
  gamma: 0.99