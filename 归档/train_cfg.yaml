seed: 42
device: 'cuda:0'

# [优化] 增加采样步数，提高 GPU 利用率
num_steps_per_env: 48 
max_iterations: 500
empirical_normalization: True

save_interval: 50
experiment_name: "dashgo_nav" 

obs_groups:
  policy: ["policy"]
  value: ["policy"]
  critic: ["policy"]

policy:
  class_name: ActorCritic 
  init_noise_std: 1.0
  actor_hidden_dims: [256, 256]
  critic_hidden_dims: [256, 256]
  activation: 'elu'

algorithm:
  class_name: PPO 
  value_loss_coef: 1.0
  use_clipped_value_loss: True
  clip_param: 0.2
  entropy_coef: 0.01
  num_learning_epochs: 5
  num_mini_batches: 4
  learning_rate: 1.0e-3
  schedule: 'adaptive'
  gamma: 0.99